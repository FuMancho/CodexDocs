URL: https://developers.openai.com/codex/pricing
Scraped: 2026-02-27T16:31:07.201399+00:00

Codex Pricing
Search the Codex docs
Primary navigation
Get started
Overview
Quickstart
Models
Pricing
Libraries
Latest: GPT-5.2
Core concepts
Text generation
Code generation
Images and vision
Audio and speech
Structured output
Function calling
Responses API
Agents
Overview
Build agents
Agent Builder
Node reference
Safety in building agents
Agents SDK
Deploy in your product
ChatKit
Custom theming
Widgets
Actions
Advanced integration
Optimize
Agent evals
Trace grading
Voice agents
Tools
Using tools
Connectors and MCP
Skills
Shell
Web search
Code interpreter
File search and retrieval
File search
Retrieval
More tools
Image generation
Computer use
Local shell tool
Apply patch
Run and scale
Conversation state
Background mode
Streaming
WebSocket mode
Webhooks
File inputs
Context management
Compaction
Counting tokens
Prompt caching
Prompting
Overview
Prompt engineering
Reasoning
Reasoning models
Reasoning best practices
Evaluation
Getting started
Working with evals
Prompt optimizer
External models
Best practices
Realtime API
Overview
Connect
WebRTC
WebSocket
SIP
Usage
Using realtime models
Managing conversations
Webhooks and server-side controls
Managing costs
Realtime transcription
Voice agents
Model optimization
Optimization cycle
Fine-tuning
Supervised fine-tuning
Vision fine-tuning
Direct preference optimization
Reinforcement fine-tuning
RFT use cases
Best practices
Graders
Specialized models
Image generation
Video generation
Text to speech
Speech to text
Deep research
Embeddings
Moderation
Going live
Production best practices
Latency optimization
Overview
Predicted Outputs
Priority processing
Cost optimization
Overview
Batch
Flex processing
Accuracy optimization
Safety
Safety best practices
Safety checks
Cybersecurity checks
Under 18 API Guidance
Legacy APIs
Assistants API
Migration guide
Deep dive
Tools
Resources
Terms and policies
Changelog
Your data
Permissions
Rate limits
Deprecations
MCP for deep research
Developer mode
ChatGPT Actions
Introduction
Getting started
Actions library
Authentication
Production
Data retrieval
Sending files
Getting Started
Overview
Quickstart
Explore
Pricing
Concepts
Prompting
Customization
Multi-agents
Workflows
Models
Cyber Safety
Using Codex
App
Overview
Features
Settings
Review
Automations
Worktrees
Local Environments
Commands
Troubleshooting
IDE Extension
Overview
Features
Settings
IDE Commands
Slash commands
CLI
Overview
Features
Command Line Options
Slash commands
Web
Overview
Environments
Internet Access
Integrations
GitHub
Slack
Linear
Configuration
Config File
Config Basics
Advanced Config
Config Reference
Sample Config
Rules
AGENTS.md
MCP
Skills
Multi-agents
Administration
Authentication
Security
Enterprise
Admin Setup
Governance
Managed configuration
Windows
Automation
Non-interactive Mode
Codex SDK
App Server
MCP Server
GitHub Action
Learn
Videos
Blog
Building frontend UIs with Codex and Figma
Testing Agent Skills Systematically with Evals
View all
Cookbooks
Codex Prompting Guide
Long horizon tasks with Codex
View all
Building AI Teams
Community
Ambassadors
Meetups
Releases
Changelog
Feature Maturity
Open Source
Home
Quickstart
Core Concepts
MCP Apps in ChatGPT
MCP Server
UX principles
UI guidelines
Plan
Research use cases
Define tools
Design components
Build
Set up your server
Build your ChatGPT UI
Authenticate users
Manage state
Monetize your app
Examples
Deploy
Deploy your app
Connect from ChatGPT
Test your integration
Submit your app
Guides
Optimize Metadata
Security & Privacy
Troubleshooting
Resources
Changelog
App submission guidelines
Reference
Home
Guides
Get started
Key concepts
Production readiness
Commerce specs
Agentic Checkout
Delegated Payment
Product feeds
Overview
Onboarding
Feed spec
Best practices
Home
Docs MCP
Categories
Code
Cookbooks
Guides
Videos
Topics
Agents
Audio & Voice
Computer use
Codex
Evals
gpt-oss
Fine-tuning
Image generation
Scaling
Tools
Video generation
Home
Topics
Agents
Evals
Multimodal
Text
Guardrails
Optimization
ChatGPT
Codex
gpt-oss
Contribute
Cookbook on GitHub
All posts
Recent
Building frontend UIs with Codex and Figma
Shell + Skills + Compaction: Tips for long-running agents that do real work
15 lessons learned building ChatGPT Apps
Testing Agent Skills Systematically with Evals
Supercharging Codex with JetBrains MCP at Skyscanner
Topics
General
API
Apps SDK
Audio
Codex
API Dashboard
For a limited time,
try Codex for free in ChatGPT Free and Go
, or enjoy
2x Codex rate limits
with Plus, Pro, Business and Enterprise
subscriptions.
Plus
Power a few focused coding sessions each week.
$20
/month
Get Plus
Codex on the web, in the CLI, in the IDE extension, and on iOS
Cloud-based integrations like automatic code review and Slack integration
The latest models, including GPT-5.3-Codex
GPT-5.1-Codex-Mini for up to 4x higher usage limits for local messages
Flexibly extend usage with
ChatGPT credits
Other
ChatGPT features
as part of the Plus plan
Pro
Rely on Codex for daily full-time development.
$200
/month
Get Pro
Everything in Plus and:
Priority request processing
Access to GPT-5.3-Codex-Spark (research preview), a fast Codex model for day-to-day coding tasks
6x higher usage limits for local and cloud tasks
10x more cloud-based code reviews
Other
ChatGPT features
as part of the Pro plan
Business
Bring Codex into your startup or growing business.
$30
/user/month
Try for free
Everything in Plus and:
Larger virtual machines to run cloud tasks faster
Flexibly extend usage with
ChatGPT credits
A secure, dedicated workspace with essential admin controls, SAML SSO, and MFA
No training on your business data by default.
Learn more
Other
ChatGPT features
as part of the Business plan
Enterprise & Edu
Unlock Codex for your entire organization with enterprise-grade functionality.
Contact sales
Everything in Business and:
Priority request processing
Enterprise-level security and controls, including SCIM, EKM, user analytics, domain verification, and role-based access control (
RBAC
)
Audit logs and usage monitoring via the
Compliance API
Data retention and data residency controls
Other
ChatGPT features
as part of the Enterprise plan
API Key
Great for automation in shared environments like CI.
Learn more
Codex in the CLI, SDK, or IDE extension
No cloud-based features (GitHub code review, Slack, etc.)
Delayed access to new models like GPT-5.3-Codex and GPT-5.3-Codex-Spark
Pay only for the tokens Codex uses, based on
API pricing
Frequently asked questions
What are the usage limits for my plan?
The number of Codex messages you can send depends on the size and complexity of your coding tasks and whether you run them locally or in the cloud. Small scripts or routine functions may consume only a fraction of your allowance, while larger codebases, long-running tasks, or extended sessions that require Codex to hold more context will use significantly more per message.
Local Messages
*
/ 5h
Cloud Tasks
*
/ 5h
Code Reviews / week
ChatGPT Plus
45-225
10-60
10-25
ChatGPT Pro
300-1500
50-400
100-250
ChatGPT Business
45-225
10-60
10-25
ChatGPT Enterprise & Edu
No fixed limits — usage scales with
credits
API Key
Usage-based
Not available
Not available
*The usage limits for local messages and cloud tasks share a
five-hour
window
. Additional weekly limits may apply.
Enterprise and Edu plans without flexible pricing have the same per-seat usage limits as Plus for most features.
GPT-5.1-Codex-Mini can be used for local tasks, providing up to 4x more usage.
GPT-5.3-Codex-Spark is in research preview for ChatGPT Pro users only, and isn’t available in the API at launch. Because it runs on specialized low-latency hardware, usage is governed by a separate usage limit that may adjust based on demand.
What happens when you hit usage limits?
ChatGPT Plus and Pro users who reach their usage limit can purchase additional credits to continue working without needing to upgrade their existing plan.
Business, Edu, and Enterprise plans with
flexible pricing
can purchase additional workspace credits to continue using Codex.
If you are approaching usage limits, you can also switch to the GPT-5.1-Codex-Mini model to make your usage limits last longer.
All users may also run extra local tasks using an API key, with usage charged at
standard API rates
.
Where can I see my current usage limits?
You can find your current limits in the
Codex usage dashboard
. If you want to see your remaining limits during an active Codex CLI session, you can use
/status
.
How do credits work?
Credits let you continue using Codex after you reach your included usage limits. Usage draws down from your available credits based on the models and features you use, allowing you to extend work without interruption.
Credit cost per message varies based on task size, complexity, and the reasoning required. The table shows average credit costs; these averages also apply to legacy GPT-5.2, GPT-5.2-Codex, GPT-5.1, GPT-5.1-Codex-Max, GPT-5, GPT-5-Codex, and GPT-5-Codex-Mini. Average rates may evolve over time as new capabilities are introduced.
Unit
GPT-5.3-Codex, GPT-5.2-Codex
GPT-5.1-Codex-Mini
Local Tasks
1 message
~5 credits
~1 credit
Cloud Tasks
1 message
~25 credits
Not available
Code Review
1 pull request
~25 credits
Not available
Learn more about credits in ChatGPT Plus and Pro.
Learn more about credits in ChatGPT Business, Enterprise, and Edu.
What counts as Code Review usage?
Code Review usage applies only when Codex runs reviews through GitHub—for example, when you tag
@Codex
for review in a pull request or enable automatic reviews on your repository. Reviews run locally or outside of GitHub count toward your general usage limits.
What can I do to make my usage limits last longer?
The usage limits and credits above are average rates. You can try the following tips to maximize your limits:
Control the size of your prompts.
Be precise with the instructions you give Codex, but remove unnecessary context.
Reduce the size of your AGENTS.md.
If you work on a larger project, you can control how much context you inject through AGENTS.md files by
nesting them within your repository
.
Limit the number of MCP servers you use.
Every
MCP
you add to Codex adds more context to your messages and uses more of your limit. Disable MCP servers when you don’t need them.
Switch to GPT-5.1-Codex-Mini for routine tasks.
Using the mini model should extend your usage limits by roughly 4x.
URL: https://developers.openai.com/codex/changelog?type=codex-cli
Scraped: 2026-02-27T16:32:03.077208+00:00

Codex changelog
Search the Codex docs
Primary navigation
Get started
Overview
Quickstart
Models
Pricing
Libraries
Latest: GPT-5.2
Core concepts
Text generation
Code generation
Images and vision
Audio and speech
Structured output
Function calling
Responses API
Agents
Overview
Build agents
Agent Builder
Node reference
Safety in building agents
Agents SDK
Deploy in your product
ChatKit
Custom theming
Widgets
Actions
Advanced integration
Optimize
Agent evals
Trace grading
Voice agents
Tools
Using tools
Connectors and MCP
Skills
Shell
Web search
Code interpreter
File search and retrieval
File search
Retrieval
More tools
Image generation
Computer use
Local shell tool
Apply patch
Run and scale
Conversation state
Background mode
Streaming
WebSocket mode
Webhooks
File inputs
Context management
Compaction
Counting tokens
Prompt caching
Prompting
Overview
Prompt engineering
Reasoning
Reasoning models
Reasoning best practices
Evaluation
Getting started
Working with evals
Prompt optimizer
External models
Best practices
Realtime API
Overview
Connect
WebRTC
WebSocket
SIP
Usage
Using realtime models
Managing conversations
Webhooks and server-side controls
Managing costs
Realtime transcription
Voice agents
Model optimization
Optimization cycle
Fine-tuning
Supervised fine-tuning
Vision fine-tuning
Direct preference optimization
Reinforcement fine-tuning
RFT use cases
Best practices
Graders
Specialized models
Image generation
Video generation
Text to speech
Speech to text
Deep research
Embeddings
Moderation
Going live
Production best practices
Latency optimization
Overview
Predicted Outputs
Priority processing
Cost optimization
Overview
Batch
Flex processing
Accuracy optimization
Safety
Safety best practices
Safety checks
Cybersecurity checks
Under 18 API Guidance
Legacy APIs
Assistants API
Migration guide
Deep dive
Tools
Resources
Terms and policies
Changelog
Your data
Permissions
Rate limits
Deprecations
MCP for deep research
Developer mode
ChatGPT Actions
Introduction
Getting started
Actions library
Authentication
Production
Data retrieval
Sending files
Getting Started
Overview
Quickstart
Explore
Pricing
Concepts
Prompting
Customization
Multi-agents
Workflows
Models
Cyber Safety
Using Codex
App
Overview
Features
Settings
Review
Automations
Worktrees
Local Environments
Commands
Troubleshooting
IDE Extension
Overview
Features
Settings
IDE Commands
Slash commands
CLI
Overview
Features
Command Line Options
Slash commands
Web
Overview
Environments
Internet Access
Integrations
GitHub
Slack
Linear
Configuration
Config File
Config Basics
Advanced Config
Config Reference
Sample Config
Rules
AGENTS.md
MCP
Skills
Multi-agents
Administration
Authentication
Security
Enterprise
Admin Setup
Governance
Managed configuration
Windows
Automation
Non-interactive Mode
Codex SDK
App Server
MCP Server
GitHub Action
Learn
Videos
Blog
Building frontend UIs with Codex and Figma
Testing Agent Skills Systematically with Evals
View all
Cookbooks
Codex Prompting Guide
Long horizon tasks with Codex
View all
Building AI Teams
Community
Ambassadors
Meetups
Releases
Changelog
Feature Maturity
Open Source
Home
Quickstart
Core Concepts
MCP Apps in ChatGPT
MCP Server
UX principles
UI guidelines
Plan
Research use cases
Define tools
Design components
Build
Set up your server
Build your ChatGPT UI
Authenticate users
Manage state
Monetize your app
Examples
Deploy
Deploy your app
Connect from ChatGPT
Test your integration
Submit your app
Guides
Optimize Metadata
Security & Privacy
Troubleshooting
Resources
Changelog
App submission guidelines
Reference
Home
Guides
Get started
Key concepts
Production readiness
Commerce specs
Agentic Checkout
Delegated Payment
Product feeds
Overview
Onboarding
Feed spec
Best practices
Home
Docs MCP
Categories
Code
Cookbooks
Guides
Videos
Topics
Agents
Audio & Voice
Computer use
Codex
Evals
gpt-oss
Fine-tuning
Image generation
Scaling
Tools
Video generation
Home
Topics
Agents
Evals
Multimodal
Text
Guardrails
Optimization
ChatGPT
Codex
gpt-oss
Contribute
Cookbook on GitHub
All posts
Recent
Building frontend UIs with Codex and Figma
Shell + Skills + Compaction: Tips for long-running agents that do real work
15 lessons learned building ChatGPT Apps
Testing Agent Skills Systematically with Evals
Supercharging Codex with JetBrains MCP at Skyscanner
Topics
General
API
Apps SDK
Audio
Codex
API Dashboard
All updates
General
Codex app
Codex CLI
February 2026
January 2026
December 2025
November 2025
October 2025
September 2025
August 2025
June 2025
May 2025
February 2026
2026-02-26
Codex CLI
0.106.0
$
npm
install
-g
@openai/codex@0.106.0
View details
New Features
Added a direct install script for macOS and Linux and publish it as a GitHub release asset, using the existing platform payload (including
codex
and
rg
) (
#12740
)
Expanded the app-server v2 thread API with experimental thread-scoped realtime endpoints/notifications and a
thread/unsubscribe
flow to unload live threads without archiving them (
#12715
,
#10954
)
Promoted
js_repl
to
/experimental
, added startup compatibility checks with user-visible warnings, and lowered the validated minimum Node version to
22.22.0
(
#12712
,
#12824
,
#12857
)
Enabled
request_user_input
in Default collaboration mode (not just Plan mode) (
#12735
)
Made
5.3-codex
visible in the CLI model list for API users (
#12808
)
Improved memory behavior with diff-based forgetting and usage-aware memory selection (
#12900
,
#12909
)
Bug Fixes
Improved realtime websocket reliability by retrying timeout-related HTTP 400 handshake failures and preferring WebSocket v2 when supported by the selected model (
#12791
,
#12838
)
Fixed a zsh-fork shell execution path that could drop sandbox wrappers and bypass expected filesystem restrictions (
#12800
)
Added a shared ~1M-character input size cap in the TUI and app-server to prevent hangs/crashes on oversized pastes, with explicit error responses (
#12823
)
Improved TUI local file-link rendering to hide absolute paths while preserving visible line/column references (
#12705
,
#12870
)
Fixed
Ctrl-C
handling for sub-agents in the TUI (
#12911
)
Documentation
Fixed a stale sign-in success link in the auth/onboarding flow (
#12805
)
Clarified the CLI login hint for remote/device-auth login scenarios (
#12813
)
Chores
Added structured OTEL audit logging for embedded
codex-network-proxy
policy decisions and blocks (
#12046
)
Removed the
steer
feature flag and standardized on the always-on steer path in the TUI composer (
#12026
)
Reduced sub-agent startup overhead by skipping expensive history metadata scans for subagent spawns (
#12918
)
Changelog
Full Changelog:
rust-v0.105.0...rust-v0.106.0
#12046
feat(network-proxy): add embedded OTEL policy audit logging
@mcgrew-oai
#12712
Promote js_repl to experimental with Node requirement
@fjord-oai
#12715
Add app-server v2 thread realtime API
@aibrahim-oai
#12795
Revert "fix(bazel): replace askama templates with include_str! in memories"
@jif-oai
#12791
Handle websocket timeout
@pakrym-oai
#12800
fix: enforce sandbox envelope for zsh fork execution
@bolinfest
#12802
Propagate session ID when compacting
@rasmusrygaard
#12732
feat(app-server): add ThreadItem::DynamicToolCall
@owenlin0
#12807
Add simple realtime text logs
@aibrahim-oai
#12805
Update Codex docs success link
@etraut-openai
#12809
fix: harden zsh fork tests and keep subcommand approvals deterministic
@bolinfest
#12808
make 5.3-codex visible in cli for api users
@sayan-oai
#10954
feat(app-server): thread/unsubscribe API
@owenlin0
#12806
only use preambles for realtime
@aibrahim-oai
#12830
Revert "only use preambles for realtime"
@aibrahim-oai
#12721
Revert "Ensure shell command skills trigger approval (
#12697
)"
@celia-oai
#12831
only use preambles for realtime
@aibrahim-oai
#12735
Enable request_user_input in Default mode
@charley-oai
#12814
feat: scope execve session approvals by approved skill metadata
@bolinfest
#12026
Remove steer feature flag
@aibrahim-oai
#12740
Add macOS and Linux direct install script
@EFRAZER-oai
#12838
Use websocket v2 as model-preferred websocket protocol
@pakrym-oai
#12811
Revert "Add skill approval event/response (
#12633
)"
@celia-oai
#12758
feat: include available decisions in command approval requests
@bolinfest
#12824
Disable js_repl when Node is incompatible at startup
@fjord-oai
#12813
Clarify device auth login hint
@xl-openai
#12848
Try fixing windows pipeline
@pakrym-oai
#12856
Attempt 2 to fix release
@pakrym-oai
#12744
Skip system skills for extra roots
@xl-openai
#12857
Reduce js_repl Node version requirement to 22.22.0
@fjord-oai
#12865
Fix release build take
@pakrym-oai
#12705
Hide local file link destinations in TUI markdown
@pash-openai
#12823
Enforce user input length cap
@etraut-openai
#12417
core: bundle settings diff updates into one dev/user envelope
@charley-oai
#12884
chore: new agents name
@jif-oai
#12885
nit: captial
@jif-oai
#12870
tui: restore visible line numbers for hidden file links
@pash-openai
#12684
Add rollout path to memory files and search for them during read
@wendyjiao-openai
#12901
chore: better awaiter description
@jif-oai
#12900
feat: memories forgetting
@jif-oai
#12905
chore: clean DB runtime
@jif-oai
#12918
Skip history metadata scan for subagents
@daveaitel-openai
#12871
split-debuginfo
@pakrym-oai
#12909
feat: use memory usage for selection
@jif-oai
#12887
fix: do not apply turn cwd to metadata
@jif-oai
#12911
fix: ctrl c sub agent
@jif-oai
#12873
Use model catalog default for reasoning summary fallback
@pakrym-oai
Full release on Github
2026-02-25
Codex CLI
0.105.0
$
npm
install
-g
@openai/codex@0.105.0
View details
New Features
The TUI now syntax-highlights fenced code blocks and diffs, adds a
/theme
picker with live preview, and uses better theme-aware diff colors for light and dark terminals. (
#11447
,
#12581
)
You can now dictate prompts by holding the spacebar to record and transcribe voice input directly in the TUI. This feature is still under development; to enable it set features.voice_transcription = true in your config. (
#3381
)
Multi-agent workflows are easier to run and track:
spawn_agents_on_csv
can fan out work from a CSV with built-in progress/ETA, and sub-agents are easier to follow with nicknames, a cleaner picker, and visible child-thread approval prompts. (
#10935
,
#12320
,
#12327
,
#12332
,
#12570
,
#12767
)
The TUI picked up new convenience commands:
/copy
copies the latest complete assistant reply, while
/clear
and
Ctrl-L
clear the screen without losing thread context, with
/clear
also able to start a fresh chat. (
#12444
,
#12520
,
#12613
,
#12628
)
Approval controls are more flexible: Codex can now ask for extra sandbox permissions for a command, and you can auto-reject specific approval prompt types without turning approvals off entirely. (
#11871
,
#12087
)
App-server clients can do more with threads:
thread/list
can search by title, thread status is exposed in read/list responses and notifications, and
thread/resume
returns the latest turn inline so reconnects are less lossy. (
#11776
,
#11786
,
#12578
)
Bug Fixes
Long links in the TUI stay clickable when wrapped, which also fixes related clipping and layout issues in several views. (
#12067
)
Several TUI interaction edge cases were fixed: queued-message editing now works in more terminals, follow-up prompts no longer get stuck if you press Enter while a final answer is still streaming, and approval dialogs now respond with the correct request id. (
#12240
,
#12569
,
#12746
)
@
parsing in the chat composer is more reliable, so commands like
npx -y @scope/pkg@latest
no longer accidentally open the file picker or block submission. (
#12643
)
App-server websocket handling is more robust: thread listeners survive disconnects, Ctrl-C waits for in-flight turns before restarting, and websocket clients that send
permessage-deflate
can connect successfully. (
#12373
,
#12517
,
#12629
)
Linux sandboxed commands now get a minimal
/dev
, fixing failures in tools that need entropy or other standard device nodes. (
#12081
)
js_repl
now reports uncaught kernel failures more clearly, recovers cleanly afterward, and correctly attaches
view_image
results from nested tool calls. (
#12636
,
#12725
)
Documentation
Added a public security policy with Bugcrowd reporting guidance. (
#12193
)
Updated install and local workflow docs to use
cargo install --locked cargo-nextest
and to avoid routine
--all-features
builds unless you specifically need full feature coverage. (
#12377
,
#12429
)
Changelog
Full Changelog:
rust-v0.104.0...rust-v0.105.0
#12071
Use V2 websockets if feature enabled
@pakrym-oai
#12052
feat(core): zsh exec bridge
@owenlin0
#12072
Add message phase to agent message thread item
@mousseau-oai
#12077
got rid of experimental_mode for configtoml
@won-openai
#12036
codex-api: realtime websocket session.create + typed inbound events
@aibrahim-oai
#12073
Add model-visible context layout snapshot tests
@charley-oai
#12096
Updated issue labeler script to include safety-check label
@etraut-openai
#11944
[js_repl] paths for node module resolution can be specified for js_repl
@aaronl-openai
#11798
fix: Restricted Read: /System is too permissive for macOS platform de…
@leoshimo-oai
#12015
Enable default status line indicators in TUI config
@jif-oai
#12124
feat: phase 1 and phase 2 e2e latencies
@jif-oai
#12121
feat: phase 2 usage
@jif-oai
#12120
feat: memory usage metrics
@jif-oai
#12133
feat: validate agent config file paths
@jif-oai
#12137
nit: change model for phase 1
@jif-oai
#12069
Stop filtering model tools in js_repl_tools_only mode
@fjord-oai
#12135
feat: better slug for rollout summaries
@jif-oai
#12157
Disable collab tools during review delegation
@jif-oai
#11802
Fixed a hole in token refresh logic for app server
@etraut-openai
#12105
fix: file watcher
@jif-oai
#12167
memories: bump rollout summary slug cap to 60
@zuxin-oai
#12177
js_repl: canonicalize paths for node_modules boundary checks
@fjord-oai
#12025
app-server support for Windows sandbox setup.
@iceweasel-oai
#12187
fix: Remove citation
@zuxin-oai
#12180
[apps] Temporary app block.
@mzeng-openai
#11786
app-server: expose loaded thread status via read/list and notifications
@euroelessar
#12038
state: enforce 10 MiB log caps for thread and threadless process logs
@charley-oai
#12203
Stabilize app-server detached review and running-resume tests
@charley-oai
#12211
[apps] Update apps allowlist.
@mzeng-openai
#12081
fix(linux-sandbox): mount /dev in bwrap sandbox
@viyatb-oai
#12164
Update docs links for feature flag notice
@etraut-openai
#12231
Adjust memories rollout defaults
@jif-oai
#12152
feat: sub-agent injection
@jif-oai
#12233
feat: add shell snapshot failure reason
@jif-oai
#12193
docs: add codex security policy
@viyatb-oai
#12228
feat: add configurable write_stdin timeout
@jif-oai
#11787
Adjust MCP tool approval handling for custom servers
@colby-oai
#12179
Move previous turn context tracking into ContextManager history
@charley-oai
#12244
Restore phase when loading from history
@mousseau-oai
#12101
client side modelinfo overrides
@sayan-oai
#12251
Add configurable agent spawn depth
@jif-oai
#12254
chore: increase stack size for everyone
@jif-oai
#12250
feat: no timeout mode on ue
@jif-oai
#12255
chore: consolidate new() and initialize() for McpConnectionManager
@bolinfest
#12256
Revert "feat: no timeout mode on ue"
@jif-oai
#12258
Undo stack size Bazel test hack
@charley-oai
#12264
Fix flaky test
@jif-oai
#12087
feat: add Reject approval policy with granular prompt rejection controls
@bolinfest
#12253
Skip removed features during metrics emission
@jif-oai
#12265
Clarify cumulative proposed_plan behavior in Plan mode
@charley-oai
#12266
app-server tests: reduce intermittent nextest LEAK via graceful child shutdown
@bolinfest
#11953
ws turn metadata via client_metadata
@pash-openai
#11778
fix(bazel): replace askama templates with include_str! in memories
@rupurt
#11382
Add configurable MCP OAuth callback URL for MCP login
@dkumar-oai
#12274
[bazel] Fix proc_macro_dep libs
@zbarsky-openai
#12054
feat(config): add permissions.network proxy config wiring
@viyatb-oai
#12269
tests(thread_resume): interrupt running turns in resume error-path tests
@bolinfest
#12009
Update pnpm versions to fix
cve-2026-24842
@mjr-openai
#12080
skill-creator: lazy-load PyYAML in frontmatter parsing
@xl-openai
#12271
tests: centralize in-flight turn cleanup helper
@bolinfest
#12286
app-server: fix flaky list_apps_returns_connectors_with_accessible_flags test
@bolinfest
#11776
app-server: improve thread resume rejoin flow
@maxj-oai
#11822
[apps] Store apps tool cache in disk to reduce startup time.
@mzeng-openai
#12221
memories: add rollout_summary_file header to raw memories and tune prompts
@zuxin-oai
#12309
Set memories phase reasoning effort constants
@jif-oai
#12315
chore: nit explorer
@jif-oai
#12320
feat: add nick name to sub-agents
@jif-oai
#12328
chore: better agent names
@jif-oai
#12326
disable collab for phase 2
@jif-oai
#12267
Add MCP server context to otel tool_result logs
@colby-oai
#12327
feat: cleaner TUI for sub-agents
@jif-oai
#12332
feat: better agent picker in TUI
@jif-oai
#12344
feat: do not enqueue phase 2 if not necessary
@jif-oai
#12340
fix: simplify macOS sleep inhibitor FFI
@yvolovich-cyber
#12347
fix: nick name at thread/read
@jif-oai
#12294
Reuse connection between turns
@pakrym-oai
#12287
app-server: add JSON tracing logs
@maxj-oai
#12140
Refactor network approvals to host/protocol/port scope
@viyatb-oai
#12300
js_repl: block wrapped payload prefixes in grammar
@fjord-oai
#11368
fix(network-proxy): add unix socket allow-all and update seatbelt rules
@viyatb-oai
#12275
js_repl: remove codex.state helper references
@fjord-oai
#12289
CODEX-4927: Surface local login entitlement denials in browser
@daniel-oai
#12205
ci(bazel): install Node from node-version.txt in remote image
@fjord-oai
#12312
feat: add config
allow_login_shell
@jif-oai
#12086
[apps] Implement apps configs.
@mzeng-openai
#12353
fix(core): require approval for destructive MCP tool calls
@colby-oai
#12218
app-server: harden disconnect cleanup paths
@maxj-oai
#12291
core tests: use hermetic mock server in review suite
@viyatb-oai
#12374
[apps] Enforce simple logo url format.
@mzeng-openai
#12377
docs: use --locked when installing cargo-nextest
@derekf-oai
#12370
Add ability to attach extra files to feedback
@pakrym-oai
#12306
Move sanitizer into codex-secrets
@viyatb-oai
#12379
clarify model_catalog_json only applied on startup
@sayan-oai
#12307
Show model/reasoning hint when switching modes
@charley-oai
#12403
[apps] Fix gateway url.
@mzeng-openai
#12240
fix(tui): queued-message edit shortcut unreachable in some terminals
@fcoury
#12405
[apps] Bump MCP tool call timeout.
@mzeng-openai
#12406
fix: explicitly list name collisions in JSON schema generation
@bolinfest
#12301
Add field to Thread object for the latest rename set for a given thread
@natea-oai
#12268
Wire realtime api to core
@aibrahim-oai
#12415
fix(nix): include libcap dependency on linux builds
@rgodha24
#12416
Add experimental realtime websocket URL override
@aibrahim-oai
#12303
Improve Plan mode reasoning selection flow
@charley-oai
#12418
Add experimental realtime websocket overrides and text mirroring
@aibrahim-oai
#12381
fix: address flakiness in thread_resume_rejoins_running_thread_even_with_override_mismatch
@bolinfest
#12422
feat: use OAI Responses API MessagePhase type directly in App Server v2
@bolinfest
#12376
test(app-server): wait for turn/completed in turn_start tests
@yvolovich-cyber
#12408
ignore v1 in JSON schema codegen
@bolinfest
#12314
fix(core) Filter non-matching prefix rules
@dylan-hurd-oai
#12429
feat: discourage the use of the --all-features flag
@bolinfest
#12252
Fix compaction context reinjection and model baselines
@charley-oai
#12427
chore: move config diagnostics out of codex-core
@bolinfest
#12430
Collapse waited message
@pakrym-oai
#12432
chore: remove codex-core public protocol/shell re-exports
@bolinfest
#12434
fix: codex-arg0 no longer depends on codex-core
@bolinfest
#12435
refactor(core): move embedded system skills into codex-skills crate
@bolinfest
#12440
chore: delete empty codex-rs/code file
@bolinfest
#12441
Delete AggregatedStream
@pakrym-oai
#11293
feat(linux-sandbox): implement proxy-only egress via TCP-UDS-TCP bridge
@viyatb-oai
#12410
profile-level model_catalog_json overrie
@sayan-oai
#12420
Prevent replayed runtime events from forcing active status
@etraut-openai
#12428
Prefer v2 websockets if available
@pakrym-oai
#12419
Improve token usage estimate for images
@etraut-openai
#12474
fix: make skills loader tests hermetic with ~/.agents skills
@bolinfest
#12473
core: preserve constrained approval/sandbox policies in TurnContext
@bolinfest
#12067
fix(tui): preserve URL clickability across all TUI views
@fcoury
#12469
Route inbound realtime text into turn start or steer
@aibrahim-oai
#12479
Revert "Route inbound realtime text into turn start or steer"
@aibrahim-oai
#12475
fix: make realtime conversation flake test order-insensitive
@bolinfest
#12476
Make shell detection tests
robust to Nix shell paths
@rupurt
#11447
feat(tui): syntax highlighting via syntect with theme picker
@fcoury
#12373
app-server: retain thread listener across disconnects
@maxj-oai
#12444
feat(tui) /clear
@won-openai
#12485
fix(core) exec policy parsing 3
@dylan-hurd-oai
#12423
Send events to realtime api
@aibrahim-oai
#12364
feat: monitor role
@jif-oai
#12313
Handle orphan exec ends without clobbering active exploring cell
@jif-oai
#12455
feat(tui): support Alt-d delete-forward-word
@dougEfresh
#12480
Revert "Revert "Route inbound realtime text into turn start or steer""
@aibrahim-oai
#12509
Sort themes case-insensitively in picker
@etraut-openai
#12511
Add C# syntax option to highlight selections
@etraut-openai
#12513
Add PR babysitting skill for this repo
@etraut-openai
#12518
test: vendor zsh fork via DotSlash and stabilize zsh-fork tests
@bolinfest
#12553
Return image content from view_image
@pakrym-oai
#12555
refactor: decouple MCP policy construction from escalate server
@bolinfest
#12559
chore: nit name
@jif-oai
#12562
chore: awaiter
@jif-oai
#12565
chore: add doc to memories
@jif-oai
#12568
chore: phase 2 name
@jif-oai
#12571
fix: TUI constraint
@jif-oai
#12570
feat: keep dead agents in the agent picker
@jif-oai
#12575
feat: agent nick names to model
@jif-oai
#12500
feat: add uuid helper
@jif-oai
#12580
chore: rename memory feature flag
@jif-oai
#12541
Allow exec resume to parse output-last-message flag after command
@etraut-openai
#12579
feat: role metrics multi-agent
@jif-oai
#12141
feat: land sqlite
@jif-oai
#12576
chore: better bazel test logs
@jif-oai
#12028
remove feature flag collaboration modes
@aibrahim-oai
#12520
tweaked /clear to support clear + new chat, also fix minor bug for macos terminal
@won-openai
#12556
refactor: normalize unix module layout for exec-server and shell-escalation
@bolinfest
#12421
app-server: box request dispatch future to reduce stack pressure
@charley-oai
#12528
chore(deps): bump libc from 0.2.180 to 0.2.182 in /codex-rs
@dependabot
#12529
chore(deps): bump syn from 2.0.114 to 2.0.117 in /codex-rs
@dependabot
#12583
Use Arc-based ToolCtx in tool runtimes
@bolinfest
#12540
fix: add ellipsis for truncated status indicator
@sayan-oai
#12609
fix(tui): recover on owned wrap mapping mismatch
@fcoury
#12569
fix(tui): queue steer Enter while final answer is still streaming to prevent dead state
@guidedways
#12530
chore(deps): bump owo-colors from 4.2.3 to 4.3.0 in /codex-rs
@dependabot
#12549
fix: show command running in background terminal in details under status indicator
@sayan-oai
#3381
voice transcription
@nornagon-openai
#12619
Handle realtime spawn_transcript delegation
@aibrahim-oai
#11408
Update models.json @github-actions
#12629
app-server: fix connecting via websockets with
Sec-WebSocket-Extensions: permessage-deflate
@JaviSoto
#12632
refactor: delete exec-server and move execve wrapper into shell-escalation
@bolinfest
#12638
refactor: decouple shell-escalation from codex-core
@bolinfest
#12357
feat(core): persist network approvals in execpolicy
@viyatb-oai
#12648
fix(exec) Patch resume test race condition
@dylan-hurd-oai
#12049
Support implicit skill invocation analytics events
@alexsong-oai
#12647
Avoid
AbsolutePathBuf::parent()
panic under
EMFILE
by skipping re-absolutization
@etraut-openai
#12633
Add skill approval event/response
@pakrym-oai
#12650
chore: rm hardcoded PRESETS list
@sayan-oai
#12652
Simplify skill tracking
@pakrym-oai
#12653
memories: tighten consolidation prompt schema and indexing guidance
@zuxin-oai
#12667
feat: mutli agents persist config overrides
@jif-oai
#12635
memories: tighten memory lookup guidance and citation requirements
@zuxin-oai
#12663
fix: replay after
/agent
@jif-oai
#11258
Send warmup request
@pakrym-oai
#12688
feat: use process group to kill the PTY
@jif-oai
#11871
feat(core) Introduce Feature::RequestPermissions
@dylan-hurd-oai
#12628
ctrl-L (clears terminal but does not start a new chat)
@won-openai
#9859
feat(network-proxy): add MITM support and gate limited-mode CONNECT
@viyatb-oai
#12649
feat: run zsh fork shell tool via shell-escalation
@bolinfest
#12643
Fix @mention token parsing in chat composer
@etraut-openai
#12658
fix: also try matching namespaced prefix for modelinfo candidate
@sayan-oai
#11766
feat(sleep-inhibitor): add Linux and Windows idle-sleep prevention
@yvolovich-cyber
#12581
feat(tui): add theme-aware diff backgrounds with capability-graded palettes
@fcoury
#12697
Ensure shell command skills trigger approval
@pakrym-oai
#12707
refactor: remove unused seatbelt unix socket arg
@bolinfest
#12687
Add TUI realtime conversation mode
@aibrahim-oai
#12639
Honor
project_root_markers
when discovering
AGENTS.md
@etraut-openai
#10935
Agent jobs (spawn_agents_on_csv) + progress UI
@daveaitel-openai
#12700
revert audio scope
@nornagon-openai
#12711
fix: temp remove citation
@zuxin-oai
#12613
feat(tui) - /copy
@won-openai
#12695
Add app-server event tracing
@pakrym-oai
#12717
Raise image byte estimate for compaction token accounting
@etraut-openai
#12724
fix: make EscalateServer public and remove shell escalation wrappers
@bolinfest
#12517
codex-rs/app-server: graceful websocket restart on Ctrl-C
@maxj-oai
#12636
fix(js_repl): surface uncaught kernel errors and reset cleanly
@fjord-oai
#12729
fix: clarify the value of SkillMetadata.path
@bolinfest
#12719
feat: pass helper executable paths via Arg0DispatchPaths
@bolinfest
#12720
add AWS_LC_SYS_NO_JITTER_ENTROPY=1 to release musl build step to unblock releases
@sayan-oai
#12725
Fix js_repl view_image attachments in nested tool calls
@fjord-oai
#12656
chore: change catalog mode to enum
@sayan-oai
#12731
chore: migrate additional permissions to PermissionProfile
@celia-oai
#12407
tests(js_repl): stabilize CI runtime test execution
@fjord-oai
#12737
feat:  add experimental additionalPermissions to v2 command execution approval requests
@celia-oai
#12372
feat: update Docker image digest to reflect
#12205
@fjord-oai
#12746
fix: chatwidget was not honoring approval_id for an ExecApprovalRequestEvent
@bolinfest
#12185
tests(js_repl): remove node-related skip paths from js_repl tests
@fjord-oai
#12358
feat(ui): add network approval persistence plumbing
@viyatb-oai
#12730
feat: zsh-fork forces scripts/**/* for skills to trigger a prompt
@bolinfest
#12750
fix: keep shell escalation exec paths absolute
@bolinfest
#12753
Surface skill permission profiles in zsh-fork exec approvals
@celia-oai
#12319
feat: add service name to app-server
@jif-oai
#12692
fix: flaky test due to second-resolution for thread ordering
@jif-oai
#12578
feat: add search term to thread list
@jif-oai
#12660
Support external agent config detect and import
@alexsong-oai
#12756
feat: record whether a skill script is approved for the session
@bolinfest
#12767
Display pending child-thread approvals in TUI
@jif-oai
#12768
feat: add large stack test macro
@jif-oai
#12666
feat: adding stream parser
@jif-oai
#12761
feat: record memory usage
@jif-oai
#12772
nit: migration
@jif-oai
#12352
otel: add host.name resource attribute to logs/traces via gethostname
@mcgrew-oai
#12770
chore: unify max depth parameter
@jif-oai
#12787
feat: fix sqlite home
@jif-oai
Full release on Github
2026-02-18
Codex CLI
0.104.0
$
npm
install
-g
@openai/codex@0.104.0
View details
New Features
Added
WS_PROXY
/
WSS_PROXY
environment support (including lowercase variants) for websocket proxying in the network proxy. (
#11784
)
App-server v2 now emits notifications when threads are archived or unarchived, enabling clients to react without polling. (
#12030
)
Protocol/core now carry distinct approval IDs for command approvals to support multiple approvals within a single shell command execution flow. (
#12051
)
Bug Fixes
Ctrl+C
/
Ctrl+D
now cleanly exits the cwd-change prompt during resume/fork flows instead of implicitly selecting an option. (
#12040
)
Reduced false-positive safety-check downgrade behavior by relying on the response header model (and websocket top-level events) rather than the response body model slug. (
#12061
)
Documentation
Updated docs and schemas to cover websocket proxy configuration, new thread archive/unarchive notifications, and the command approval ID plumbing. (
#11784
,
#12030
,
#12051
)
Chores
Made the Rust release workflow resilient to
npm publish
attempts for an already-published version. (
#12044
)
Standardized remote compaction test mocking and refreshed related snapshots to align with the default production-shaped behavior. (
#12050
)
Changelog
Full Changelog:
rust-v0.103.0...rust-v0.104.0
#11784
feat(network-proxy): add websocket proxy env support
@viyatb-oai
#12044
don't fail if an npm publish attempt is for an existing version.
@iceweasel-oai
#12040
tui: exit session on Ctrl+C in cwd change prompt
@charley-oai
#12030
app-server: Emit thread archive/unarchive notifications
@euroelessar
#12061
Chore: remove response model check and rely on header model for downgrade
@shijie-oai
#12051
feat(core): plumb distinct approval ids for command approvals
@owenlin0
#12050
Unify remote compaction snapshot mocks around default endpoint behavior
@charley-oai
Full release on Github
2026-02-17
Codex app
26.217
New features
Added drag-and-drop support to reorder queued messages.
Added a warning when the selected model is downgraded.
Improvements and bug fixes
Improved file workflows with fuzzy file search and better attachment recovery after restart.
Additional performance improvements and bug fixes.
2026-02-17
Codex CLI
0.103.0
$
npm
install
-g
@openai/codex@0.103.0
View details
New Features
App listing responses now include richer app details (
app_metadata
, branding, and labels), so clients can render more complete app cards without extra requests. (
#11706
)
Commit co-author attribution now uses a Codex-managed
prepare-commit-msg
hook, with
command_attribution
override support (default label, custom label, or disable). (
#11617
)
Bug Fixes
Removed the
remote_models
feature flag to prevent fallback model metadata when it was disabled, improving model selection reliability and performance. (
#11699
)
Chores
Updated Rust dependencies (
clap
,
env_logger
,
arc-swap
) and refreshed Bazel lock state as routine maintenance. (
#11888
,
#11889
,
#11890
,
#12032
)
Reverted the Rust toolchain bump to
1.93.1
after CI breakage. (
#11886
,
#12035
)
Changelog
Full Changelog:
rust-v0.102.0...rust-v0.103.0
#11699
chore: rm remote models fflag
@sayan-oai
#11706
[apps] Expose more fields from apps listing endpoints.
@mzeng-openai
#11890
chore(deps): bump arc-swap from 1.8.0 to 1.8.2 in /codex-rs
@dependabot
#11886
chore(deps): bump rust-toolchain from 1.93.0 to 1.93.1 in /codex-rs
@dependabot
#12032
chore: just bazel-lock-update
@bolinfest
#11888
chore(deps): bump clap from 4.5.56 to 4.5.58 in /codex-rs
@dependabot
#11889
chore(deps): bump env_logger from 0.11.8 to 0.11.9 in /codex-rs
@dependabot
#11617
Use prompt-based co-author attribution with config override
@gabec-openai
#12035
Revert "chore(deps): bump rust-toolchain from 1.93.0 to 1.93.1 in /co…dex-rs (
#11886
)"
@etraut-openai
Full release on Github
2026-02-17
Codex CLI
0.102.0
$
npm
install
-g
@openai/codex@0.102.0
View details
New Features
Added a more unified permissions flow, including clearer permissions history in the TUI and a slash command to grant sandbox read access when directories are blocked. (
#11633
,
#11512
,
#11550
,
#11639
)
Introduced structured network approval handling, with richer host/protocol context shown directly in approval prompts. (
#11672
,
#11674
)
Expanded app-server fuzzy file search with explicit session-complete signaling so clients can stop loading indicators reliably. (
#10268
,
#11773
)
Added customizable multi-agent roles via config, including migration toward the new multi-agent naming/config surface. (
#11917
,
#11982
,
#11939
,
#11918
)
Added a
model/rerouted
notification so clients can detect and render model reroute events explicitly. (
#12001
)
Bug Fixes
Fixed remote image attachments so they persist correctly across resume/backtrack and history replay in the TUI. (
#10590
)
Fixed a TUI accessibility regression where animation gating for screen reader users was not consistently respected. (
#11860
)
Fixed app-server thread resume behavior to correctly rejoin active in-memory threads and tighten invalid resume cases. (
#11756
)
Fixed
model/list
output to return full model data plus visibility metadata, avoiding unintended server-side filtering. (
#11793
)
Fixed several
js_repl
stability issues, including reset hangs, in-flight tool-call races, and a
view_image
panic path. (
#11932
,
#11922
,
#11800
,
#11796
)
Fixed app integration edge cases in mention parsing and app list loading/filtering behavior. (
#11894
,
#11518
,
#11697
)
Documentation
Updated contributor guidance to require snapshot coverage for user-visible TUI changes. (
#10669
)
Updated docs/help text around Codex app and MCP command usage. (
#11926
,
#11813
)
Chores
Improved developer log tooling with new
just log --search
and
just log --compact
modes. (
#11995
,
#11994
)
Updated vendored
rg
and tightened Bazel/Cargo lockfile sync checks to reduce dependency drift. (
#12007
,
#11790
)
Changelog
Full Changelog:
rust-v0.101.0...rust-v0.102.0
#10268
app-server: add fuzzy search sessions for streaming file search
@nornagon-openai
#11547
Parse first order skill/connector mentions
@canvrno-oai
#11227
feat(app-server): experimental flag to persist extended history
@owenlin0
#10672
Add js_repl host helpers and exec end events
@fjord-oai
#11512
add a slash command to grant sandbox read access to inaccessible directories
@iceweasel-oai
#11631
chore(core) Deprecate approval_policy: on-failure
@dylan-hurd-oai
#11636
Better error message for model limit hit.
@xl-openai
#11633
feat: introduce Permissions
@bolinfest
#10669
docs: require insta snapshot coverage for UI changes
@joshka-oai
#11645
fix: skip review_start_with_detached_delivery_returns_new_thread_id o…
@owenlin0
#11639
[feat] add seatbelt permission files
@celia-oai
#11622
Remove absolute path in rollout_summary
@wendyjiao-openai
#10671
Add js_repl_tools_only model and routing restrictions
@fjord-oai
#11657
app-server tests: disable shell_snapshot for review suite
@bolinfest
#11646
app-server: stabilize detached review start on Windows
@bolinfest
#11638
fix(app-server): surface more helpful errors for json-rpc
@owenlin0
#11417
[apps] Add is_enabled to app info.
@mzeng-openai
#11630
Add new apps_mcp_gateway
@canvrno-oai
#11656
Persist complete TurnContextItem state via canonical conversion
@charley-oai
#11510
Remove git commands from dangerous command checks
@joshka-oai
#11668
feat(shell-tool-mcp): add patched zsh build pipeline
@nornagon-openai
#11275
Added a test to verify that feature flags that are enabled by default are stable
@etraut-openai
#11651
Add cwd as an optional field to thread/list
@acrognale-oai
#11660
chore(approvals) More approvals scenarios
@dylan-hurd-oai
#11518
[apps] Fix app loading logic.
@mzeng-openai
#11679
fix: dont show NUX for upgrade-target models that are hidden
@sayan-oai
#11515
Point Codex App tooltip links to app landing page
@joshka-oai
#11671
chore(core) Restrict model-suggested rules
@dylan-hurd-oai
#11703
fix(ci) lock rust toolchain at 1.93.0 to unblock
@dylan-hurd-oai
#11662
feat(network-proxy): structured policy signaling and attempt correlation to core
@viyatb-oai
#11709
fix(shell-tool-mcp) build dependencies
@dylan-hurd-oai
#11618
feat: add token usage on memories
@jif-oai
#11722
Lower missing rollout log level
@jif-oai
#11712
chore: streamline phase 2
@jif-oai
#11731
feat: memories config
@jif-oai
#11736
feat: increase windows workers stack
@jif-oai
#11739
feat: add slug in name
@jif-oai
#11745
chore: move explorer to spark
@jif-oai
#11748
Fix memories output schema requirements
@jif-oai
#11669
core: limit search_tool_bm25 to Apps and clarify discovery guidance
@apanasenko-oai
#11755
app-server-test-client websocket client and thread tools
@maxj-oai
#11663
fix: reduce flakiness of compact_resume_after_second_compaction_preserves_history
@bolinfest
#11667
sandbox NUX metrics update
@iceweasel-oai
#11695
Updated app bug report template
@etraut-openai
#11477
feat: switch on dying sub-agents
@jif-oai
#11711
feat(tui): prevent macOS idle sleep while turns run
@yvolovich-cyber
#11686
Report syntax errors in rules file
@etraut-openai
#11763
Update read_path prompt
@zuxin-oai
#11772
chore: mini
@jif-oai
#11697
[apps] Improve app listing filtering.
@mzeng-openai
#11666
Add js_repl kernel crash diagnostics
@fjord-oai
#11687
support app usage analytics
@alexsong-oai
#11769
Improve GitHub issue deduplication reliability by introducing a stage…
@etraut-openai
#11770
fix(nix): use correct version from Cargo.toml in flake build
@rupurt
#11677
turn metadata: per-turn non-blocking
@pash-openai
#11692
rmcp-client: fix auth crash
@maxj-oai
#10590
tui: preserve remote image attachments across resume/backtrack
@charley-oai
#11782
turn metadata followups
@pash-openai
#11773
[app-server] add fuzzyFileSearch/sessionCompleted
@nornagon-openai
#11756
codex-rs: fix thread resume rejoin semantics
@maxj-oai
#11793
fix: send unfiltered models over model/list
@sayan-oai
#11799
fix(protocol): make local image test Bazel-friendly
@joshka-oai
#11796
Fix js_repl view_image test runtime panic
@fjord-oai
#11800
Fix js_repl in-flight tool-call waiter race
@fjord-oai
#11658
feat(skills): add permission profiles from openai.yaml metadata
@celia-oai
#11790
bazel: enforce MODULE.bazel.lock sync with Cargo.lock
@joshka-oai
#11803
add perf metrics for connectors load
@alexsong-oai
#11659
Handle model-switch base instructions after compaction
@charley-oai
#11813
Fixed help text for
mcp
and
mcp-server
CLI commands
@etraut-openai
#11672
feat(core): add structured network approval plumbing and policy decision model
@viyatb-oai
#11674
feat(tui): render structured network approval prompts in approval overlay
@viyatb-oai
#11550
feat(tui) Permissions update history item
@dylan-hurd-oai
#11767
fix(core): add linux bubblewrap sandbox tag
@viyatb-oai
#11534
Add process_uuid to sqlite logs
@charley-oai
#11487
core: snapshot tests for compaction requests, post-compaction layout, some additional compaction tests
@charley-oai
#11690
fix: show user warning when using default fallback metadata
@sayan-oai
#11780
chore(tui): reduce noisy key logging
@apanasenko-oai
#11884
fix: only emit unknown model warning on user turns
@sayan-oai
#11893
bazel: fix snapshot parity for tests/*.rs rust_test targets
@apanasenko-oai
#11759
feat: use shell policy in shell snapshot
@jif-oai
#11615
Allow hooks to error
@gt-oai
#11918
chore: rename collab feature flag key to multi_agent
@jif-oai
#11924
nit: memory storage
@jif-oai
#11917
feat: add customizable roles for multi-agents
@jif-oai
#11926
docs: mention Codex app in README intro
@vb-openai
#11900
feat: drop MCP managing tools if no MCP servers
@jif-oai
#11939
Rename collab modules to multi agents
@jif-oai
#11894
[apps] Fix app mention syntax.
@mzeng-openai
#11866
chore(core) rm Feature::RequestRule
@dylan-hurd-oai
#11948
add(feedback): over-refusal / safety check
@fouad-openai
#11860
Fixed screen reader regression in CLI
@etraut-openai
#11964
add(core): safety check downgrade warning
@fouad-openai
#11951
fix(core) exec_policy parsing fixes
@dylan-hurd-oai
#11932
fix: js_repl reset hang by clearing exec tool calls without waiting
@jif-oai
#11974
Hide /debug slash commands from popup menu
@jif-oai
#11922
fix: race in js repl
@jif-oai
#11969
fix(ci) Fix shell-tool-mcp.yml
@dylan-hurd-oai
#11908
Exit early when session initialization fails
@jif-oai
#11986
nit: wording multi-agent
@jif-oai
#11995
feat: add
--search
to
just log
@jif-oai
#11994
feat: add
--compact
mode to
just log
@jif-oai
#11833
Don't allow model_supports_reasoning_summaries to disable reasoning
@etraut-openai
#11807
Centralize context update diffing logic
@charley-oai
#12007
Update vendored rg to the latest stable version (15.1)
@etraut-openai
#11970
Protect workspace .agents directory in Windows sandbox
@etraut-openai
#12005
Add /statusline tooltip entry
@jif-oai
#11982
feat: move agents config to main config
@jif-oai
#11224
chore: clarify web_search deprecation notices and consolidate tests
@sayan-oai
#12001
Feat: add model reroute notification
@shijie-oai
#11801
Add remote skill scope/product_surface/enabled params and cleanup
@xl-openai
Full release on Github
2026-02-12
Codex app
26.212
New features
Support for GPT-5.3-Codex-Spark
Added conversation forking
Added
floating pop-out window
to take a conversation with you
Bug fixes
Improved performance and bug fixes
Alpha testing for the Codex app on Windows is also starting.
Sign up here
to be a potential alpha tester.
2026-02-12
Introducing GPT-5.3-Codex-Spark
Today, we’re releasing a research preview of GPT-5.3-Codex-Spark
,
a smaller version of GPT-5.3-Codex and our first model designed for real-time
coding. Codex-Spark is optimized to feel near-instant, delivering more than 1000 tokens per second while remaining highly capable for real-world coding tasks.
Codex-Spark is available in research preview for ChatGPT Pro users in
the latest Codex app, CLI, and IDE extension. This release also marks the first
milestone in our partnership with Cerebras.
At launch, Codex-Spark is text-only with a 128k context window. During
the research preview, usage has separate model-specific limits and doesn’t
count against standard Codex limits. During high demand, access may slow down
or queue while we balance reliability across users.
To switch to GPT-5.3-Codex-Spark:
In the CLI, start a new thread with:
codex
--model
gpt-5.3-codex-spark
Or use
/model
during a session.
In the IDE extension, choose GPT-5.3-Codex-Spark from the model selector in
the composer.
In the Codex app, choose GPT-5.3-Codex-Spark from the model selector in the
composer.
If you don’t see GPT-5.3-Codex-Spark yet, update the CLI, IDE extension, or
Codex app to the latest version.
GPT-5.3-Codex-Spark isn’t available in the API at launch.
For API-key workflows, continue using
gpt-5.2-codex
.
2026-02-12
Codex CLI
0.101.0
$
npm
install
-g
@openai/codex@0.101.0
View details
Bug Fixes
Model resolution now preserves the requested model slug when selecting by prefix, so model references stay stable instead of being rewritten. (
#11602
)
Developer messages are now excluded from phase-1 memory input, reducing noisy or irrelevant content entering memory. (
#11608
)
Memory phase processing concurrency was reduced to make consolidation/staging more stable under load. (
#11614
)
Chores
Cleaned and simplified the phase-1 memory pipeline code paths. (
#11605
)
Minor repository maintenance: formatting and test-suite hygiene updates in remote model tests. (
#11619
)
Changelog
Full Changelog:
rust-v0.100.0...rust-v0.101.0
#11605
chore: drop and clean from phase 1
@jif-oai
#11602
fix(core) model_info preserves slug
@dylan-hurd-oai
#11608
exclude developer messages from phase-1 memory input
@wendyjiao-openai
#11591
Add cwd to memory files
@wendyjiao-openai
#11614
chore: reduce concurrency of memories
@jif-oai
#11619
fix: fmt
@jif-oai
Full release on Github
2026-02-12
Codex CLI
0.100.0
$
npm
install
-g
@openai/codex@0.100.0
View details
New Features
Added an experimental, feature-gated JavaScript REPL runtime (
js_repl
) that can persist state across tool calls, with optional runtime path overrides. (
#10674
)
Added support for multiple simultaneous rate limits across the protocol, backend client, and TUI status surfaces. (
#11260
)
Reintroduced app-server websocket transport with a split inbound/outbound architecture, plus connection-aware thread resume subscriptions. (
#11370
,
#11474
)
Added memory management slash commands in the TUI (
/m_update
,
/m_drop
) and expanded memory-read/metrics plumbing. (
#11569
,
#11459
,
#11593
)
Enabled Apps SDK apps in ChatGPT connector handling. (
#11486
)
Promoted sandbox capabilities on both Linux and Windows, and introduced a new
ReadOnlyAccess
policy shape for configurable read access. (
#11381
,
#11341
,
#11387
)
Bug Fixes
Fixed websocket incremental output duplication, prevented appends after
response.completed
, and treated
response.incomplete
as an error path. (
#11383
,
#11402
,
#11558
)
Improved websocket session stability by continuing ping handling when idle and suppressing noisy first-retry errors during quick reconnects. (
#11413
,
#11548
)
Fixed stale thread entries by dropping missing rollout files and cleaning stale DB metadata during thread listing. (
#11572
)
Fixed Windows multi-line paste reliability in terminals (especially VS Code integrated terminal) by increasing paste burst timing tolerance. (
#9348
)
Fixed incorrect inheritance of
limit_name
when merging partial rate-limit updates. (
#11557
)
Reduced repeated skill parse-error spam during active edits by increasing file-watcher debounce from 1s to 10s. (
#11494
)
Documentation
Added JS REPL documentation and config/schema guidance for enabling and configuring the feature. (
#10674
)
Updated app-server websocket transport documentation in the app-server README. (
#11370
)
Chores
Split
codex-common
into focused
codex-utils-*
crates to simplify dependency boundaries across Rust workspace components. (
#11422
)
Improved Rust release pipeline throughput and reliability for Windows and musl targets, including parallel Windows builds and musl link fixes. (
#11488
,
#11500
,
#11556
)
Prevented GitHub release asset upload collisions by excluding duplicate
cargo-timing.html
artifacts. (
#11564
)
Changelog
Full Changelog:
rust-v0.99.0...rust-v0.100.0
#11383
Do not resend output items in incremental websockets connections
@pakrym-oai
#11246
chore: persist turn_id in rollout session and make turn_id uuid based
@celia-oai
#11260
feat: support multiple rate limits
@xl-openai
#11412
tui: show non-file layer content in /debug-config
@bolinfest
#11405
Remove
test-support
feature from
codex-core
and replace it with explicit test toggles
@bolinfest
#11428
fix: flaky test
@jif-oai
#11429
feat: improve thread listing
@jif-oai
#11422
feat: split codex-common into smaller utils crates
@bolinfest
#11439
feat: new memory prompts
@jif-oai
#11305
Cache cloud requirements
@gt-oai
#11452
nit: increase max raw memories
@jif-oai
#11455
feat: close mem agent after consolidation
@jif-oai
#11454
fix: optional schema of memories
@jif-oai
#11449
feat: set policy for phase 2 memory
@jif-oai
#11420
chore: rename disable_websockets -> websockets_disabled
@sayan-oai
#11402
Do not attempt to append after response.completed
@pakrym-oai
#11462
clean: memory rollout recorder
@jif-oai
#11381
feat(core): promote Linux bubblewrap sandbox to Experimental
@viyatb-oai
#11389
Extract
codex-config
from
codex-core
@bolinfest
#11370
Reapply "Add app-server transport layer with websocket support"
@maxj-oai
#11470
feat: panic if Constrained does not support Disabled
@bolinfest
#11475
feat: remove "cargo check individual crates" from CI
@bolinfest
#11459
feat: memory read path
@jif-oai
#11471
chore: clean rollout extraction in memories
@jif-oai
#9348
fix(tui): increase paste burst char interval on Windows to 30ms
@yuvrajangadsingh
#11464
chore: sub-agent never ask for approval
@jif-oai
#11414
Linkify feedback link
@pakrym-oai
#11480
chore: update mem prompt
@jif-oai
#11485
fix: Constrained import
@owenlin0
#11341
Promote Windows Sandbox
@iceweasel-oai
#10674
Add feature-gated freeform js_repl core runtime
@fjord-oai
#11419
refactor: codex app-server ThreadState
@maxj-oai
#11413
Pump pings
@pakrym-oai
#11488
feat: use more powerful machines for building Windows releases
@bolinfest
#11479
nit: memory truncation
@jif-oai
#11494
Increased file watcher debounce duration from 1s to 10s
@etraut-openai
#11335
Add AfterToolUse hook
@gt-oai
#11500
feat: build windows support binaries in parallel
@bolinfest
#11290
chore(tui) Simplify /status Permissions
@dylan-hurd-oai
#11503
Make codex-sdk depend on openai/codex
@pakrym-oai
#11474
app-server: thread resume subscriptions
@maxj-oai
#11277
Added seatbelt policy rule to allow os.cpus
@etraut-openai
#11506
chore: inject originator/residency headers to ws client
@apanasenko-oai
#11497
Hydrate previous model across resume/fork/rollback/task start
@aibrahim-oai
#11513
feat: try to fix bugs I saw in the wild in the resource parsing logic
@bolinfest
#11509
Consolidate search_tool feature into apps
@apanasenko-oai
#11388
change model cap to server overload
@willwang-openai
#11504
Pre-sampling compact with previous model context
@aibrahim-oai
#11516
Clamp auto-compact limit to context window
@aibrahim-oai
#11520
Update context window after model switch
@aibrahim-oai
#11519
Use slug in tui
@pakrym-oai
#11522
fix: add --test_verbose_timeout_warnings to bazel.yml
@bolinfest
#11526
fix: remove errant Cargo.lock files
@bolinfest
#11521
test(app-server): stabilize app/list thread feature-flag test by using file-backed MCP OAuth creds
@bolinfest
#11387
feat: make sandbox read access configurable with
ReadOnlyAccess
@bolinfest
#11486
[apps] Allow Apps SDK apps.
@mzeng-openai
#11532
fix compilation
@sayan-oai
#11531
Teach codex to test itself
@pakrym-oai
#11540
ci: remove actions/cache from rust release workflows
@bolinfest
#11542
ci(windows): use DotSlash for zstd in rust-release-windows
@bolinfest
#11498
build(linux-sandbox): always compile vendored bubblewrap on Linux; remove CODEX_BWRAP_ENABLE_FFI
@viyatb-oai
#11545
fix: make project_doc skill-render tests deterministic
@bolinfest
#11543
ci: capture cargo timings in Rust CI and release workflows
@bolinfest
#11539
Bump rmcp to 0.15
@gpeal
#11548
Hide the first websocket retry
@pakrym-oai
#11551
Add logs to model cache
@aibrahim-oai
#11556
Fix rust-release failures in musl linking and release asset upload
@bolinfest
#11558
Handle response.incomplete
@pakrym-oai
#11557
fix: stop inheriting rate-limit limit_name
@xl-openai
#11564
rust-release: exclude cargo-timing.html from release assets
@bolinfest
#11546
fix: update memory writing prompt
@zuxin-oai
#11448
Fix test flake
@gt-oai
#11569
feat: mem slash commands
@jif-oai
#11573
Fix flaky pre_sampling_compact switch test
@jif-oai
#11571
feat: mem drop cot
@jif-oai
#11572
Ensure list_threads drops stale rollout files
@jif-oai
#11575
fix: db stuff mem
@jif-oai
#11581
nit: upgrade DB version
@jif-oai
#11577
feat: truncate with model infos
@jif-oai
#11590
chore: clean consts
@jif-oai
#11593
feat: metrics to memories
@jif-oai
#11579
Fix config test on macOS
@gt-oai
#11600
feat: add sanitizer to redact secrets
@jif-oai
#11609
chore: drop mcp validation of dynamic tools
@jif-oai
Full release on Github
2026-02-11
Codex CLI
0.99.0
$
npm
install
-g
@openai/codex@0.99.0
View details
New Features
Running direct shell commands no longer interrupts an in-flight turn; commands can execute concurrently when a turn is active. (
#10513
)
Added
/statusline
to configure which metadata appears in the TUI footer interactively. (
#10546
)
The TUI resume picker can now toggle sort order between creation time and last-updated time with an in-picker mode indicator. (
#10752
)
App-server clients now get dedicated APIs for steering active turns, listing experimental features, resuming agents, and opting out of specific notifications. (
#10721
,
#10821
,
#10903
,
#11319
)
Enterprise/admin requirements can now restrict web search modes and define network constraints through
requirements.toml
. (
#10964
,
#10958
)
Image attachments now accept GIF and WebP inputs in addition to existing formats. (
#11237
)
Enable snapshotting of the shell environment and
rc
files (
#11172
)
Bug Fixes
Fixed a Windows startup issue where buffered keypresses could cause the TUI sign-in flow to exit immediately. (
#10729
)
Required MCP servers now fail fast during start/resume flows instead of continuing in a broken state. (
#10902
)
Fixed a file-watcher bug that emitted spurious skills reload events and could generate very large log files. (
#11217
)
Improved TUI input reliability: long option labels wrap correctly, Tab submits in steer mode when idle, history recall keeps cursor placement consistent, and stashed drafts restore image placeholders correctly. (
#11123
,
#10035
,
#11295
,
#9040
)
Fixed model-modality edge cases by surfacing clearer
view_image
errors on text-only models and stripping unsupported image history during model switches. (
#11336
,
#11349
)
Reduced false approval mismatches for wrapped/heredoc shell commands and guarded against empty command lists in exec policy evaluation. (
#10941
,
#11397
)
Documentation
Expanded app-server docs and protocol references for
turn/steer
, experimental-feature discovery,
resume_agent
, notification opt-outs, and null
developer_instructions
normalization. (
#10721
,
#10821
,
#10903
,
#10983
,
#11319
)
Updated TUI composer docs to reflect draft/image restoration, steer-mode Tab submit behavior, and history-navigation cursor semantics. (
#9040
,
#10035
,
#11295
)
Chores
Reworked npm release packaging so platform-specific binaries are distributed via
@openai/codex
dist-tags, reducing package-size pressure while preserving platform-specific installs (including
@alpha
). (
#11318
,
#11339
)
Pulled in a security-driven dependency update for
time
(RUSTSEC-2026-0009). (
#10876
)
Changelog
Full Changelog:
rust-v0.98.0...rust-v0.99.0
#10729
fix(tui): flush input buffer on init to prevent early exit on Windows
@Ashutosh0x
#10689
fix: flaky landlock
@jif-oai
#10513
Allow user shell commands to run alongside active turns
@jif-oai
#10738
nit: backfill stronger
@jif-oai
#10246
adding fork information (UI) when forking
@pap-openai
#10748
Update explorer role default model
@jif-oai
#10425
Include real OS info in metrics.
@iceweasel-oai
#10745
feat: resumable backfill
@jif-oai
#10758
feat: wire ephemeral in
codex exec
@jif-oai
#10756
chore: handle shutdown correctly in tui
@jif-oai
#10637
feat: add memory tool
@jif-oai
#10751
feat: repair DB in case of missing lines
@jif-oai
#10762
nit: add DB version in discrepancy recording
@jif-oai
#10621
Leverage state DB metadata for thread summaries
@jif-oai
#9691
Add hooks implementation and wire up to
notify
@gt-oai
#10546
feat(tui): add /statusline command for interactive status line configuration
@fcoury
#10752
feat(tui): add sortable resume picker with created/updated timestamp toggle
@fcoury
#10769
fix(tui): fix resume_picker_orders_by_updated_at test
@owenlin0
#10423
fix(auth): isolate chatgptAuthTokens concept to auth manager and app-server
@owenlin0
#10775
nit: gpt-5.3-codex announcement
@jif-oai
#10782
nit: gpt-5.3-codex announcement 2
@jif-oai
#10711
add sandbox policy and sandbox name to codex.tool.call metrics
@iceweasel-oai
#10660
chore: rm web-search-eligible header
@sayan-oai
#10783
fix: announcement in prio
@jif-oai
#10721
[app-server] Add a method to list experimental features.
@mzeng-openai
#10787
chore: limit update to 0.98.0 NUX to < 0.98.0 ver
@sayan-oai
#10655
Add analytics for /rename and /fork
@pap-openai
#10790
feat: wait for backfill to be ready
@jif-oai
#10693
Add app-server transport layer with websocket support
@maxj-oai
#10818
other announcement
@jif-oai
#10815
Sync app-server requirements API with refreshed cloud loader
@xl-openai
#10820
go back to auto-enabling web_search for azure
@sayan-oai
#10727
Send beta header with websocket connects
@pakrym-oai
#10809
updates: use brew api for version check
@magus
#10793
Add stage field for experimental flags.
@mzeng-openai
#10821
feat(app-server): turn/steer API
@owenlin0
#10792
Print warning when config does not meet requirements
@gt-oai
#10699
feat: expose detailed metrics to runtime metrics
@apanasenko-oai
#10784
Gate app tooltips to macOS
@aibrahim-oai
#10843
Log an event (info only) when we receive a file watcher event
@etraut-openai
#10852
Personality setting is no longer available in experimental menu
@etraut-openai
#10840
Removed the "remote_compaction" feature flag
@etraut-openai
#10876
sec: fix version of
time
to prevent vulnerability
@jif-oai
#10892
nit: test an
@jif-oai
#10894
feat: backfill async again
@jif-oai
#10902
Handle required MCP startup failures across components
@jif-oai
#10851
Removed "exec_policy" feature flag
@etraut-openai
#10457
Queue nudges while plan generating
@charley-oai
#10822
Add app configs to config.toml
@canvrno-oai
#10420
feat(network-proxy): add structured policy decision to blocked errors
@viyatb-oai
#10814
fix(linux-sandbox): block io_uring syscalls in no-network seccomp policy
@viyatb-oai
#10698
core: preconnect Responses websocket for first turn
@joshka-oai
#10574
core: refresh developer instructions after compaction replacement history
@charley-oai
#10914
chore(app-server): update AGENTS.md for config + optional collection guidance
@owenlin0
#10928
chore(app-server): add experimental annotation to relevant fields
@owenlin0
#10927
Treat compaction failure as failure state
@aibrahim-oai
#10861
Support alternative websocket API
@by-openai
#10826
add originator to otel
@alexsong-oai
#10855
TUI/Core: preserve duplicate skill/app mention selection across submit + resume
@daniel-oai
#10943
app-server: print help message to console when starting websockets server
@JaviSoto
#10938
Mark Config.apps as experimental, correct schema generation issue
@canvrno-oai
#10947
fix(tui): conditionally restore status indicator using message phase
@sayan-oai
#10965
refactor(network-proxy): flatten network config under [network]
@viyatb-oai
#10970
Fixed a flaky test
@etraut-openai
#10710
Process-group cleanup for stdio MCP servers to prevent orphan process storms
@etraut-openai
#10964
feat: add support for allowed_web_search_modes in requirements.toml
@bolinfest
#10977
fix: use expected line ending in codex-rs/core/config.schema.json
@bolinfest
#10973
Do not poll for usage when using API Key auth
@etraut-openai
#10921
Show left/right arrows to navigate in tui request_user_input
@charley-oai
#10988
fix: normalize line endings when reading file on Windows
@bolinfest
#10903
Add resume_agent collab tool
@jif-oai
#10909
Bootstrap shell commands via user shell snapshot
@jif-oai
#10993
Fix flaky windows CI test
@etraut-openai
#10987
Fixed a flaky Windows test that is consistently causing a CI failure
@etraut-openai
#10958
feat(core): add network constraints schema to requirements.toml
@viyatb-oai
#10983
app-server: treat null mode developer instructions as built-in defaults
@charley-oai
#11039
feat: include state of [experimental_network] in /debug-config output
@bolinfest
#11040
Simplify pre-connect
@pakrym-oai
#10966
feat: enable premessage-deflate for websockets
@apanasenko-oai
#9040
fix(tui): rehydrate drafts and restore image placeholders
@Chriss4123
#10824
Fallback to HTTP on UPGRADE_REQUIRED
@pakrym-oai
#11028
Defer persistence of rollout file
@etraut-openai
#10980
fix: remove config.schema.json from tag check
@bolinfest
#11051
Gate view_image tool by model input_modalities
@wiltzius-openai
#11109
[bazel] Upgrade some rulesets in preparation for enabling windows
@zbarsky-openai
#11114
chore: refactor network-proxy so that ConfigReloader is injectable behavior
@bolinfest
#10718
Upgrade rmcp to 0.14
@mzeng-openai
#11044
feat: include [experimental_network] in <environment_context>
@bolinfest
#10994
[apps] Improve app loading.
@mzeng-openai
#11121
chore: reverse the codex-network-proxy -> codex-core dependency
@bolinfest
#11105
feat: include NetworkConfig through ExecParams
@bolinfest
#11155
tui: avoid no-op status-line redraws
@rakan-oai
#10799
feat: do not close unified exec processes across turns
@jif-oai
#11172
chore: enable shell snapshot
@jif-oai
#11175
fix: do not show closed agents in
/agent
@jif-oai
#11173
chore: enable sub agents
@jif-oai
#11193
Deflake mixed parallel tools timing test
@gt-oai
#10770
Load requirements on windows
@gt-oai
#11132
core: account for all post-response items in auto-compact token checks
@charley-oai
#11198
tools: remove get_memory tool and tests
@jif-oai
#10937
Translate websocket errors
@rasmusrygaard
#11217
Fixed bug in file watcher that results in spurious skills update events and large log files
@etraut-openai
#11216
Move warmup to the task level
@pakrym-oai
#11203
Try to stop small helper methods
@pakrym-oai
#11197
[bazel] Upgrade some rulesets in preparation for enabling windows, part 2
@zbarsky-openai
#11158
chore: remove network-proxy-cli crate
@viyatb-oai
#11230
Revert "chore: enable sub agents"
@jif-oai
#11123
TUI: fix request_user_input wrapping for long option labels
@charley-oai
#11133
core: add focused diagnostics for remote compaction overflows
@charley-oai
#10657
feat: search_tool
@apanasenko-oai
#11199
state: add memory consolidation lock primitives
@jif-oai
#10835
feat: extend skills/list to support additional roots.
@xl-openai
#10960
skill-creator: Remove invalid reference.
@xl-openai
#11219
feat: use a notify instead of grace to close ue process
@jif-oai
#11231
feat: tie shell snapshot to cwd
@jif-oai
#10962
fix(tui): keep unified exec summary on working line
@joshka-oai
#11232
Add originator to otel metadata tags
@alexsong-oai
#11237
adding image support for gif and webp
@natea-oai
#10924
[apps] Add gated instructions for Apps.
@mzeng-openai
#11228
Use longest remote model prefix matching
@aibrahim-oai
#11242
fix(feature) UnderDevelopment feature must be off
@dylan-hurd-oai
#11185
fix: nix build by adding missing dependencies and fix outputHashes
@Philipp-M
#10035
fix(tui): tab submits when no task running in steer mode
@joshka-oai
#11238
Remove offline fallback for models
@aibrahim-oai
#9739
Update models.json @github-actions
#11255
Revert "Update models.json"
@aibrahim-oai
#11245
deflake linux-sandbox NoNewPrivs timeout
@joshka-oai
#11256
Revert "Revert "Update models.json""
@aibrahim-oai
#11262
chore: change ConfigState so it no longer depends on a single config.toml file for reloading
@bolinfest
#11263
test: deflake nextest child-process leak in MCP harnesses
@joshka-oai
#11247
Adjust shell command timeouts for Windows
@dylan-hurd-oai
#11240
fix(app-server): for external auth, replace id_token with chatgpt_acc…
@owenlin0
#11140
chore(deps): bump insta from 1.46.2 to 1.46.3 in /codex-rs
@dependabot
#11139
chore(deps): bump anyhow from 1.0.100 to 1.0.101 in /codex-rs
@dependabot
#11138
chore(deps): bump regex from 1.12.2 to 1.12.3 in /codex-rs
@dependabot
#11239
Disable dynamic model refresh for custom model providers
@etraut-openai
#11269
feat: reserve loopback ephemeral listeners for managed proxy
@bolinfest
#11279
[apps] Add thread_id param to optionally load thread config for apps feature check.
@mzeng-openai
#11244
feat: add SkillPolicy to skill metadata and support allow_implicit_invocation
@alexsong-oai
#10215
chore(tui) cleanup /approvals
@dylan-hurd-oai
#11113
feat(sandbox): enforce proxy-aware network routing in sandbox
@viyatb-oai
#10940
feat: support configurable metric_exporter
@alexsong-oai
#11294
chore: put crypto provider logic in a shared crate
@bolinfest
#11207
feat: retain NetworkProxy, when appropriate
@bolinfest
#11200
memories: add extraction and prompt module foundation
@jif-oai
#11191
feat: add connector capabilities to sub-agents
@jif-oai
#11304
Fix spawn_agent input type
@jif-oai
#11300
feat: align memory phase 1 and make it stronger
@jif-oai
#11311
Extract hooks into dedicated crate
@jif-oai
#11306
feat: phase 2 consolidation
@jif-oai
#11318
chore: split NPM packages
@jif-oai
#11322
Fix pending input test waiting logic
@jif-oai
#11265
Remove ApiPrompt
@pakrym-oai
#11295
tui: keep history recall cursor at line end
@joshka-oai
#11288
fix(protocol): approval policy never prompt
@fouad-openai
#11323
Revert "Add app-server transport layer with websocket support (
#10693
)"
@maxj-oai
#11162
Fix: update parallel tool call exec approval to approve on request id
@shijie-oai
#11249
[apps] Improve app installation flow.
@mzeng-openai
#11319
feat: opt-out of events in the app-server
@jif-oai
#11241
Treat first rollout session_meta as canonical thread identity
@guinness-oai
#11339
# Use
@openai/codex
dist-tags for platform binaries instead of separate package names
@bolinfest
#11330
test(core): stabilize ARM bazel remote-model and parallelism tests
@dylan-hurd-oai
#11345
core: remove stale apply_patch SandboxPolicy TODO in seatbelt
@bolinfest
#11343
Compare full request for websockets incrementality
@pakrym-oai
#11344
fix: reduce usage of
open_if_present
@jif-oai
#11336
Always expose view_image and return unsupported image-input error
@aibrahim-oai
#11346
Sanitize MCP image output for text-only models
@aibrahim-oai
#11337
Extract tool building
@pakrym-oai
#10941
fix(core): canonicalize wrapper approvals and support heredoc prefix …
@viyatb-oai
#10946
include sandbox (seatbelt, elevated, etc.) as in turn metadata header
@iceweasel-oai
#11349
Strip unsupported images from prompt history to guard against model switch
@aibrahim-oai
#11348
Use thin LTO for alpha Rust release builds
@bolinfest
#11334
chore: unify memory job flow
@jif-oai
#11364
feat: mem v2 - PR1
@jif-oai
#11365
feat: mem v2 - PR2
@jif-oai
#11366
feat: mem v2 - PR3
@jif-oai
#11274
Update models.json @github-actions
#11361
# Split command parsing/safety out of
codex-core
into new
codex-command
@bolinfest
#11369
feat: mem v2 - PR4
@jif-oai
#11362
Enable SOCKS defaults for common local network proxy use cases
@viyatb-oai
#11359
ci: fall back to local Bazel on forks without BuildBuddy key
@joshka-oai
#11372
feat: mem v2 - PR5
@jif-oai
#11374
feat: mem v2 - PR6 (consolidation)
@jif-oai
#11377
feat: prevent double backfill
@jif-oai
#11378
chore: rename codex-command to codex-shell-command
@bolinfest
#11376
Update models.json @github-actions
#11394
Disable very flaky tests
@pakrym-oai
#11386
Prefer websocket transport when model opts in
@pakrym-oai
#11373
tui: queue non-pending rollback trims in app-event order
@charley-oai
#11393
Remove
deterministic_process_ids
feature to avoid duplicate
codex-core
builds
@bolinfest
#11397
fix(exec-policy) No empty command lists
@dylan-hurd-oai
Full release on Github
2026-02-10
Codex app
26.210
New features
Added branch search in the branch picker.
Added clearer guidance for entering plan mode when you type
plan
in the composer.
Added support for parallel approvals.
Improvements and bug fixes
Additional performance improvements and bug fixes.
2026-02-09
GPT-5.3-Codex in Cursor and VS Code
Starting today, GPT-5.3-Codex is available natively in Cursor and VS Code.
API access is starting with a small set of customers as part of a phased
release.
This is the first model treated as a high security capability under the
Preparedness Framework.
Safety controls will continue to scale, and API access will expand over the
next few weeks.
2026-02-08
Codex app
26.208
New features
Added MCP and personality actions to the command palette.
Updated follow-up behavior to queue by default.
Improvements and bug fixes
Additional performance improvements and bug fixes.
2026-02-06
Codex app
26.206
New features
Added a file-reference action to reveal files directly in your OS file manager.
Improvements and bug fixes
Improved handling of large reviews by removing the overall diff-size cap in the review pane.
Additional performance improvements and bug fixes.
2026-02-05
Codex app
26.205
New features
Support for
GPT-5.3-Codex
.
Added mid-turn steering. Submit a message while Codex is working to direct its behavior.
Attach or drop any file type.
Bug fixes
Fix flickering of the app.
2026-02-05
Introducing GPT-5.3-Codex
Today we’re releasing GPT-5.3-Codex
,
the most capable agentic coding model to date for complex, real-world software
engineering.
GPT-5.3-Codex combines the frontier coding performance of GPT-5.2-Codex with
stronger reasoning and professional knowledge capabilities, and runs 25% faster
for Codex users. It’s also better at collaboration while the agent is
working—delivering more frequent progress updates and responding to steering in
real time.
GPT-5.3-Codex is available with paid ChatGPT plans everywhere you can use
Codex: the Codex app, the CLI, the IDE extension, and Codex Cloud on the web.
API access for the model will come soon.
To switch to GPT-5.3-Codex:
In the CLI, start a new thread with:
codex
--model
gpt-5.3-codex
Or use
/model
during a session.
In the IDE extension, make sure you are signed in with ChatGPT, then choose
GPT-5.3-Codex from the model selector in the composer.
In the Codex app, make sure you are signed in with ChatGPT, then choose
GPT-5.3-Codex from the model selector in the composer.
If you don’t see GPT-5.3-Codex, update the CLI, IDE extension, or Codex app
to the latest version.
For API-key workflows, continue using
gpt-5.2-codex
while API support rolls
out.
2026-02-05
Codex CLI
0.98.0
$
npm
install
-g
@openai/codex@0.98.0
View details
New Features
Introducing GPT-5.3-Codex.
Learn More
Steer mode is now stable and enabled by default, so
Enter
sends immediately during running tasks while
Tab
explicitly queues follow-up input. (
#10690
)
Bug Fixes
Fixed
resumeThread()
argument ordering in the TypeScript SDK so resuming with local images no longer starts an unintended new session. (
#10709
)
Fixed model-instruction handling when changing models mid-conversation or resuming with a different model, ensuring the correct developer instructions are applied. (
#10651
,
#10719
)
Fixed a remote compaction mismatch where token pre-estimation and compact payload generation could use different base instructions, improving trim accuracy and avoiding context overflows. (
#10692
)
Cloud requirements now reload immediately after login instead of requiring a later refresh path to take effect. (
#10725
)
Chores
Restored the default assistant personality to Pragmatic across config and related tests/UI snapshots. (
#10705
)
Unified collaboration mode naming and metadata across prompts, tools, protocol types, and TUI labels for more consistent mode behavior and messaging. (
#10666
)
Changelog
Full Changelog:
rust-v0.97.0...rust-v0.98.0
#10709
fix: ensure resume args precede image args
@cryptonerdcn
#10705
chore(config) Default Personality Pragmatic
@dylan-hurd-oai
#10651
fix(core) switching model appends model instructions
@dylan-hurd-oai
#10666
Sync collaboration mode naming across Default prompt, tools, and TUI
@charley-oai
#10690
Make steer stable by default
@aibrahim-oai
#10692
Fix remote compaction estimator/payload instruction small mismatch
@charley-oai
#10725
Reload cloud requirements after user login
@xl-openai
#10719
fix(core,app-server) resume with different model
@dylan-hurd-oai
Full release on Github
2026-02-05
Codex CLI
0.97.0
$
npm
install
-g
@openai/codex@0.97.0
View details
New Features
Added a session-scoped “Allow and remember” option for MCP/App tool approvals, so repeated calls to the same tool can be auto-approved during the session. (
#10584
)
Added live skill update detection, so skill file changes are picked up without restarting. (
#10478
)
Added support for mixed text and image content in dynamic tool outputs for app-server integrations. (
#10567
)
Added a new
/debug-config
slash command in the TUI to inspect effective configuration. (
#10642
)
Introduced initial memory plumbing (API client + local persistence) to support thread memory summaries. (
#10629
,
#10634
)
Added configurable
log_dir
so logs can be redirected (including via
-c
overrides) more easily. (
#10678
)
Bug Fixes
Fixed jitter in the TUI apps/connectors picker by stabilizing description-column rendering. (
#10593
)
Restored and stabilized the TUI “working” status indicator/shimmer during preamble and early exec flows. (
#10700
,
#10701
)
Improved cloud requirements reliability with higher timeouts, retries, and corrected precedence over MDM settings. (
#10631
,
#10633
,
#10659
)
Persisted pending-input user events more consistently for mid-turn injected input handling. (
#10656
)
Documentation
Documented how to opt in to the experimental app-server API. (
#10667
)
Updated docs/schema coverage for new
log_dir
configuration behavior. (
#10678
)
Chores
Added a gated Bubblewrap (
bwrap
) Linux sandbox path to improve filesystem isolation options. (
#9938
)
Refactored model client lifecycle to be session-scoped and reduced implicit client state. (
#10595
,
#10664
)
Added caching for MCP actions from apps to reduce repeated load latency for users with many installed apps. (
#10662
)
Added a
none
personality option in protocol/config surfaces. (
#10688
)
Changelog
Full Changelog:
rust-v0.96.0...rust-v0.97.0
#10595
Stop client from being state carrier
@pakrym-oai
#10584
Add option to approve and remember MCP/Apps tool usage
@canvrno-oai
#10644
fix: flaky test
@jif-oai
#10629
feat: add phase 1 mem client
@jif-oai
#10633
Cloud Requirements: take precedence over MDM
@gt-oai
#10659
Increase cloud req timeout
@gt-oai
#9938
feat(linux-sandbox): add bwrap support
@viyatb-oai
#10656
Persist pending input user events
@aibrahim-oai
#10634
feat: add phase 1 mem db
@jif-oai
#10593
Fix jitter in TUI apps/connectors picker
@canvrno-oai
#10662
[apps] Cache MCP actions from apps.
@mzeng-openai
#10649
Fix test_shell_command_interruption flake
@gt-oai
#10642
Add /debug-config slash command
@gt-oai
#10478
Added support for live updates to skills
@etraut-openai
#10688
add none personality option
@aibrahim-oai
#10567
feat(app-server, core): allow text + image content items for dynamic tool outputs
@owenlin0
#10667
chore(app-server): document experimental API opt-in
@owenlin0
#10664
Session-level model client
@pakrym-oai
#10678
feat(core): add configurable log_dir
@joshka-oai
#10631
Cloud Requirements: increase timeout and retries
@gt-oai
#10650
chore(core) personality migration tests
@dylan-hurd-oai
#10701
fix(tui): restore working shimmer after preamble output
@joshka-oai
#10700
fix: ensure status indicator present earlier in exec path
@sayan-oai
Full release on Github
2026-02-04
Codex app
26.204
New features
Added
Zed
and
Textmate
as options to open files and folders.
Added PDF preview in the review panel.
Bug fixes
Performance improvements.
2026-02-04
Codex CLI
0.96.0
$
npm
install
-g
@openai/codex@0.96.0
View details
New Features
Added
thread/compact
to the v2 app-server API as an async trigger RPC, so clients can start compaction immediately and track completion separately. (
#10445
)
Added websocket-side rate limit signaling via a new
codex.rate_limits
event, with websocket parity for ETag/reasoning metadata handling. (
#10324
)
Enabled
unified_exec
on all non-Windows platforms. (
#10641
)
Constrained requirement values now include source provenance, enabling source-aware config debugging in UI flows like
/debug-config
. (
#10568
)
Bug Fixes
Fixed
Esc
handling in the TUI
request_user_input
overlay: when notes are open,
Esc
now exits notes mode instead of interrupting the session. (
#10569
)
Thread listing now queries the state DB first (including archived threads) and falls back to filesystem traversal only when needed, improving listing correctness and resilience. (
#10544
)
Fixed thread path lookup to require that the resolved file actually exists, preventing invalid thread-id resolutions. (
#10618
)
Dynamic tool injection now runs in a single transaction to avoid partial state updates. (
#10614
)
Refined
request_rule
guidance used in approval-policy prompting to correct rule behavior. (
#10379
,
#10598
)
Documentation
Updated app-server docs for
thread/compact
to clarify its asynchronous behavior and thread-busy lifecycle. (
#10445
)
Updated TUI docs to match the mode-specific
Esc
behavior in
request_user_input
. (
#10569
)
Chores
Migrated state DB helpers to a versioned SQLite filename scheme and cleaned up legacy state files during runtime initialization. (
#10623
)
Expanded runtime telemetry with websocket timing metrics and simplified internal metadata flow in core client plumbing. (
#10577
,
#10589
)
Changelog
Full Changelog:
rust-v0.95.0...rust-v0.96.0
#10569
tui: make Esc clear request_user_input notes while notes are shown
@charley-oai
#10577
feat: log webscocket timing into runtime metrics
@apanasenko-oai
#10445
Add thread/compact v2
@aibrahim-oai
#10589
Move metadata calculation out of client
@pakrym-oai
#10379
fix(core) updated request_rule guidance
@dylan-hurd-oai
#10598
fix(core) Request Rule guidance tweak
@dylan-hurd-oai
#10544
Prefer state DB thread listings before filesystem
@jif-oai
#10614
fix: single transaction for dyn tools injection
@jif-oai
#10568
Requirements: add source to constrained requirement values
@gt-oai
#10611
chore: simplify user message detection
@jif-oai
#10618
fix: make sure file exist in
find_thread_path_by_id_str_in_subdir
@jif-oai
#10619
nit: cleaning
@jif-oai
#10324
Add a codex.rate_limits event for websockets
@rasmusrygaard
#10623
Migrate state DB path helpers to versioned filename
@jif-oai
#10638
Update tests to stop using sse_completed fixture
@pakrym-oai
#10641
feat: land unified_exec
@jif-oai
Full release on Github
2026-02-04
Codex CLI
0.95.0
$
npm
install
-g
@openai/codex@0.95.0
View details
New Features
Added
codex app <path>
on macOS to launch Codex Desktop from the CLI, with automatic DMG download if it is missing. (
#10418
)
Added personal skill loading from
~/.agents/skills
(with
~/.codex/skills
compatibility), plus app-server APIs/events to list and download public remote skills. (
#10437
,
#10448
)
/plan
now accepts inline prompt arguments and pasted images, and slash-command editing/highlighting in the TUI is more polished. (
#10269
)
Shell-related tools can now run in parallel, improving multi-command execution throughput. (
#10505
)
Shell executions now receive
CODEX_THREAD_ID
, so scripts and skills can detect the active thread/session. (
#10096
)
Added vendored Bubblewrap + FFI wiring in the Linux sandbox as groundwork for upcoming runtime integration. (
#10413
)
Bug Fixes
Hardened Git command safety so destructive or write-capable invocations no longer bypass approval checks. (
#10258
)
Improved resume/thread browsing reliability by correctly showing saved thread names and fixing thread listing behavior. (
#10340
,
#10383
)
Fixed first-run trust-mode handling so sandbox mode is reported consistently, and made
$PWD/.agents
read-only like
$PWD/.codex
. (
#10415
,
#10524
)
Fixed
codex exec
hanging after interrupt in websocket/streaming flows; interrupted turns now shut down cleanly. (
#10519
)
Fixed review-mode approval event wiring so
requestApproval
IDs align with the corresponding command execution items. (
#10416
)
Improved 401 error diagnostics by including server message/body details plus
cf-ray
and
requestId
. (
#10508
)
Documentation
Expanded TUI chat composer docs to cover slash-command arguments and attachment handling in plan/review flows. (
#10269
)
Refreshed issue templates and labeler prompts to better separate CLI/app bug reporting and feature requests. (
#10411
,
#10453
,
#10548
,
#10552
)
Chores
Completed migration off the deprecated
mcp-types
crate to
rmcp
-based protocol types/adapters, then removed the legacy crate. (
#10356
,
#10349
,
#10357
)
Updated the
bytes
dependency for a security advisory and cleaned up resolved advisory configuration. (
#10525
)
Changelog
Full Changelog:
rust-v0.94.0...rust-v0.95.0
#10340
Session picker shows thread_name if set
@pap-openai
#10381
chore: collab experimental
@jif-oai
#10231
feat: experimental flags
@jif-oai
#10382
nit: shell snapshot retention to 3 days
@jif-oai
#10383
fix: thread listing
@jif-oai
#10386
fix: Rfc3339 casting
@jif-oai
#10356
feat: add MCP protocol types and rmcp adapters
@bolinfest
#10269
Nicer highlighting of slash commands, /plan accepts prompt args and pasted images
@charley-oai
#10274
Add credits tooltip
@pakrym-oai
#10394
chore: ignore synthetic messages
@jif-oai
#10398
feat: drop sqlx logging
@jif-oai
#10281
Select experimental features with space
@pakrym-oai
#10402
feat: add
--experimental
to
generate-ts
@jif-oai
#10258
fix: unsafe auto-approval of git commands
@viyatb-oai
#10411
Updated labeler workflow prompt to include "app" label
@etraut-openai
#10399
emit a separate metric when the user cancels UAT during elevated setup
@iceweasel-oai
#10377
chore(tui) /personalities tip
@dylan-hurd-oai
#10252
[feat] persist thread_dynamic_tools in db
@celia-oai
#10437
feat: Read personal skills from .agents/skills
@gverma-openai
#10145
make codex better at git
@pash-openai
#10418
Add
codex app
macOS launcher
@aibrahim-oai
#10447
Fix plan implementation prompt reappearing after /agent thread switch
@charley-oai
#10064
TUI: Render request_user_input results in history and simplify interrupt handling
@charley-oai
#10349
feat: replace custom mcp-types crate with equivalents from rmcp
@bolinfest
#10415
Fixed sandbox mode inconsistency if untrusted is selected
@etraut-openai
#10452
Hide short worked-for label in final separator
@aibrahim-oai
#10357
chore: remove deprecated mcp-types crate
@bolinfest
#10454
app tool tip
@aibrahim-oai
#10455
chore: add phase to message responseitem
@sayan-oai
#10414
Require models refresh on cli version mismatch
@aibrahim-oai
#10271
[Codex][CLI] Gate image inputs by model modalities
@ccy-oai
#10374
Trim compaction input
@pakrym-oai
#10453
Updated bug and feature templates
@etraut-openai
#10465
Restore status after preamble
@pakrym-oai
#10406
fix: clarify deprecation message for features.web_search
@sayan-oai
#10474
Ignore remote_compact_trims_function_call_history_to_fit_context_window on windows
@pakrym-oai
#10413
feat(linux-sandbox): vendor bubblewrap and wire it with FFI
@viyatb-oai
#10142
feat(secrets): add codex-secrets crate
@viyatb-oai
#10157
chore: nuke chat/completions API
@jif-oai
#10498
feat: drop wire_api from clients
@jif-oai
#10501
feat: clean codex-api part 1
@jif-oai
#10508
Add more detail to 401 error
@gt-oai
#10521
Avoid redundant transactional check before inserting dynamic tools
@jif-oai
#10525
chore: update bytes crate in response to security advisory
@bolinfest
#10408
fix WebSearchAction type clash between v1 and v2
@sayan-oai
#10404
Cleanup collaboration mode variants
@charley-oai
#10505
Enable parallel shell tools
@jif-oai
#10532
feat:
find_thread_path_by_id_str_in_subdir
from DB
@jif-oai
#10524
fix: make $PWD/.agents read-only like $PWD/.codex
@bolinfest
#10096
Inject CODEX_THREAD_ID into the terminal environment
@maxj-oai
#10536
Revert "Load untrusted rules"
@viyatb-oai
#10412
fix(app-server): fix TS annotations for optional fields on requests
@owenlin0
#10416
fix(app-server): fix approval events in review mode
@owenlin0
#10545
Improve Default mode prompt (less confusion with Plan mode)
@charley-oai
#10289
[apps] Gateway MCP should be blocking.
@mzeng-openai
#10189
implement per-workspace capability SIDs for workspace specific ACLs
@iceweasel-oai
#10548
Updated bug templates and added a new one for app
@etraut-openai
#10531
[codex] Default values from requirements if unset
@gt-oai
#10552
Fixed icon for CLI bug template
@etraut-openai
#10039
chore(arg0): advisory-lock janitor for codex tmp paths
@viyatb-oai
#10448
feat: add APIs to list and download public remote skills
@xl-openai
#10519
Handle exec shutdown on Interrupt (fixes immortal
codex exec
with websockets)
@rasmusrygaard
#10556
Feat: add upgrade to app server modelList
@shijie-oai
#10461
feat(tui): pace catch-up stream chunking with hysteresis
@joshka-oai
#10367
chore: add
codex debug app-server
tooling
@celia-oai
Full release on Github
2026-02-03
Codex app
26.203
New features
Added thread renaming on double-click in the thread list.
Improvements and bug fixes
Renamed
Sync
to
Handoff
and added clearer source/destination stats in the handoff UI.
Additional performance improvements and bug fixes.
2026-02-02
Introducing the Codex app
Codex app
The Codex app for macOS is a desktop interface for running agent threads in parallel and collaborating with agents on long-running tasks. It includes a project sidebar, thread list, and review pane for tracking work across projects.
Key features:
Multitask across projects
Built-in worktree support
Voice dictation
Built-in Git tooling
Skills
Automations
For a limited time,
ChatGPT Free and Go include Codex
, and
Plus, Pro, Business, Enterprise, and Edu
plans get
double rate limits
. Those higher limits apply in the app, the CLI, your IDE, and the cloud.
Learn more in the
Introducing the Codex app
blog post.
Check out the
Codex app documentation
for more.
Get started with the Codex app
2026-02-02
Codex CLI
0.94.0
$
npm
install
-g
@openai/codex@0.94.0
View details
New Features
Plan mode is now enabled by default with updated interaction guidance in the plan prompt. (
#10313
,
#10308
,
#10329
)
Personality configuration is now stable: default is friendly, the config key is
personality
, and existing settings migrate forward. (
#10305
,
#10314
,
#10310
,
#10307
)
Skills can be loaded from
.agents/skills
, with clearer relative-path instructions and nested-folder markers supported. (
#10317
,
#10282
,
#10350
)
Console output now includes runtime metrics for easier diagnostics. (
#10278
)
Bug Fixes
Unarchiving a thread updates its timestamp so sidebar ordering refreshes. (
#10280
)
Conversation rules output is capped and prefix rules are deduped to avoid repeated rules. (
#10351
,
#10309
)
Override turn context no longer appends extra items. (
#10354
)
Documentation
Fixed a broken image link in the npm README. (
#10303
)
Changelog
Full Changelog:
rust-v0.93.0...rust-v0.94.0
#10278
feat: show runtime metrics in console
@apanasenko-oai
#10285
display promo message in usage error
@willwang-openai
#10302
fix(nix): update flake for newer Rust toolchain requirements
@douglaz
#10296
chore(features) remove Experimental tag from UTF8
@dylan-hurd-oai
#10303
Fix npm README image link
@fouad-openai
#10306
chore(app-server) add personality update test
@dylan-hurd-oai
#10308
plan mode prompt
@aibrahim-oai
#10305
chore(core) Default to friendly personality
@dylan-hurd-oai
#10307
feat(core,tui,app-server) personality migration
@dylan-hurd-oai
#10313
enable plan mode
@aibrahim-oai
#10120
feat: fire tracking events for skill invocation
@alexsong-oai
#10317
feat: Support loading skills from .agents/skills
@gverma-openai
#10282
Make skills prompt explicit about relative-path lookup
@xl-openai
#10316
Add websocket telemetry metrics and labels
@apanasenko-oai
#10314
chore(config) Rename config setting to personality
@dylan-hurd-oai
#10310
chore(features) Personality => Stable
@dylan-hurd-oai
#10320
Sync system skills from public repo
@gverma-openai
#10322
Sync system skills from public repo for openai yaml changes
@gverma-openai
#10323
fix(config) config schema newline
@dylan-hurd-oai
#10329
Improve plan mode interaction rules
@charley-oai
#10280
Bump thread updated_at on unarchive to refresh sidebar ordering
@charley-oai
#10350
fix: System skills marker includes nested folders recursively
@gverma-openai
#10351
fix(rules) Limit rules listed in conversation
@dylan-hurd-oai
#10354
Do not append items on override turn context
@pakrym-oai
#10309
fix(core) Deduplicate prefix_rules before appending
@dylan-hurd-oai
#10373
chore(core) gpt-5.2-codex personality template
@dylan-hurd-oai
#10375
fix(personality) prompt patch
@dylan-hurd-oai
#10371
feat: vendor app-server protocol schema fixtures
@bolinfest
Full release on Github
January 2026
2026-01-28
Web search is now enabled by default
Codex now enables web search for local tasks in the Codex CLI and IDE Extension.
By default, Codex uses a web search cache, which is an OpenAI-maintained index of web results. Cached mode returns pre-indexed results instead of fetching live pages, while live mode fetches the most recent data from the web. If you are using
--yolo
or another
full access sandbox setting
, web search defaults to live results. To disable this behavior or switch modes, use the
web_search
configuration option:
web_search = "cached"
(default; serves results from the web search cache)
web_search = "live"
(fetches the most recent data from the web; same as
--search
)
web_search = "disabled"
to remove the tool
To learn more, check out the
configuration documentation
.
2026-01-23
Team Config for shared configuration
Team Config groups the files teams use to standardize Codex across repositories and machines. Use it to share:
config.toml
defaults
rules/
for command controls outside the sandbox
skills/
for reusable workflows
Codex loads these layers from
.codex/
folders in the current working directory, parent folders, and the repo root, plus user (
~/.codex/
) and system (
/etc/codex/
) locations. Higher-precedence locations override lower-precedence ones.
Admins can still enforce constraints with
requirements.toml
, which overrides defaults regardless of location.
Learn more in
Team Config
.
2026-01-22
Custom prompts deprecated
Custom prompts are now deprecated. Use
skills
for reusable instructions and workflows instead.
2026-01-14
GPT-5.2-Codex API availability
GPT-5.2-Codex is now available in the API and for users who sign into Codex with the API.
To learn more about using GPT-5.2-Codex check out our
API documentation
.
December 2025
2025-12-19
Agent skills in Codex
Codex now supports
agent skills
: reusable bundles of instructions (plus optional scripts and resources) that help Codex reliably complete specific tasks.
Skills are available in both the Codex CLI and IDE extensions.
You can invoke a skill explicitly by typing
$skill-name
(for example,
$skill-installer
or the experimental
$create-plan
skill after installing it), or let Codex select a skill automatically based on your prompt.
Learn more in the
skills documentation
.
Folder-based standard (agentskills.io)
Following the open
agent skills specification
, a skill is a folder with a required
SKILL.md
and optional supporting files:
my-skill/
SKILL.md       # Required: instructions + metadata
scripts/       # Optional: executable code
references/    # Optional: documentation
assets/        # Optional: templates, resources
Install skills per-user or per-repo
You can install skills for just yourself in
~/.codex/skills
, or for everyone on a project by checking them into
.codex/skills
in the repository.
Codex also ships with a few built-in system skills to get started, including
$skill-creator
and
$skill-installer
. The
$create-plan
skill is experimental and needs to be installed (for example:
$skill-installer install the create-plan skill from the .experimental folder
).
Curated skills directory
Codex ships with a
small curated set of skills
inspired by popular workflows at OpenAI. Install them with
$skill-installer
, and expect more over time.
2025-12-18
Introducing GPT-5.2-Codex
Today we are releasing GPT-5.2-Codex
, the most advanced agentic coding model yet for complex, real-world software engineering.
GPT-5.2-Codex is a version of
GPT-5.2
further optimized for agentic coding in Codex, including improvements on long-horizon work through context compaction, stronger performance on large code changes like refactors and migrations, improved performance in Windows environments, and significantly stronger cybersecurity capabilities.
Starting today, the CLI and IDE Extension will default to
gpt-5.2-codex
for users who are signed in with ChatGPT. API access for the model will come soon.
If you have a model specified in your
config.toml
configuration file
, you can instead try out
gpt-5.2-codex
for a new Codex CLI session using:
codex
--model
gpt-5.2-codex
You can also use the
/model
slash command in the CLI. In the Codex IDE Extension you can select GPT-5.2-Codex from the dropdown menu.
If you want to switch for all sessions, you can change your default model to
gpt-5.2-codex
by updating your
config.toml
configuration file
:
model =
"gpt-5.2-codex”
2025-12-04
Introducing Codex for Linear
Assign or mention @Codex in an issue to kick-off a Codex cloud task. As Codex works, it posts updates back to Linear, providing a link to the completed task so you can review, open a PR, or keep working.
To learn more about how to connect Codex to Linear both locally through MCP and through the new integration, check out the
Codex for Linear documentation
.
November 2025
2025-11-24
Usage and credits fixes
Minor updates to address a few issues with Codex usage and credits:
Adjusted all usage dashboards to show “limits remaining” for consistency. The CLI previously displayed “limits used.”
Fixed an issue preventing users from buying credits if their ChatGPT subscription was purchased via iOS or Google Play.
Fixed an issue where the CLI could display stale usage information; it now refreshes without needing to send a message first.
Optimized the backend to help smooth out usage throughout the day, irrespective of overall Codex load or how traffic is routed. Before, users could get unlucky and hit a few cache misses in a row, leading to much less usage.
2025-11-18
Introducing GPT-5.1-Codex-Max
Today we are releasing GPT-5.1-Codex-Max
, our new frontier agentic coding model.
GPT‑5.1-Codex-Max is built on an update to our foundational reasoning model, which is trained on agentic tasks across software engineering, math, research, and more. GPT‑5.1-Codex-Max is faster, more intelligent, and more token-efficient at every stage of the development cycle–and a new step towards becoming a reliable coding partner.
Starting today, the CLI and IDE Extension will default to
gpt-5.1-codex-max
for users that are signed in with ChatGPT. API access for the model will come soon.
For non-latency-sensitive tasks, we’ve also added a new Extra High (
xhigh
) reasoning effort, which lets the model think for an even longer period of time for a better answer. We still recommend medium as your daily driver for most tasks.
If you have a model specified in your
config.toml
configuration file
, you can instead try out
gpt-5.1-codex-max
for a new Codex CLI session using:
codex
--model
gpt-5.1-codex-max
You can also use the
/model
slash command in the CLI. In the Codex IDE Extension you can select GPT-5.1-Codex from the dropdown menu.
If you want to switch for all sessions, you can change your default model to
gpt-5.1-codex-max
by updating your
config.toml
configuration file
:
model =
"gpt-5.1-codex-max”
2025-11-13
Introducing GPT-5.1-Codex and GPT-5.1-Codex-Mini
Along with the
GPT-5.1 launch in the API
, we are introducing new
gpt-5.1-codex-mini
and
gpt-5.1-codex
model options in Codex, a version of GPT-5.1 optimized for long-running, agentic coding tasks and use in coding agent harnesses in Codex or Codex-like harnesses.
Starting today, the CLI and IDE Extension will default to
gpt-5.1-codex
on macOS and Linux and
gpt-5.1
on Windows.
If you have a model specified in your
config.toml
configuration file
, you can instead try out
gpt-5.1-codex
for a new Codex CLI session using:
codex
--model
gpt-5.1-codex
You can also use the
/model
slash command in the CLI. In the Codex IDE Extension you can select GPT-5.1-Codex from the dropdown menu.
If you want to switch for all sessions, you can change your default model to
gpt-5.1-codex
by updating your
config.toml
configuration file
:
model =
"gpt-5.1-codex”
2025-11-07
Introducing GPT-5-Codex-Mini
Today we are introducing a new
gpt-5-codex-mini
model option to Codex CLI and the IDE Extension. The model is a smaller, more cost-effective, but less capable version of
gpt-5-codex
that provides approximately 4x more usage as part of your ChatGPT subscription.
Starting today, the CLI and IDE Extension will automatically suggest switching to
gpt-5-codex-mini
when you reach 90% of your 5-hour usage limit, to help you work longer without interruptions.
You can try the model for a new Codex CLI session using:
codex
--model
gpt-5-codex-mini
You can also use the
/model
slash command in the CLI. In the Codex IDE Extension you can select GPT-5-Codex-Mini from the dropdown menu.
Alternatively, you can change your default model to
gpt-5-codex-mini
by updating your
config.toml
configuration file
:
model =
"gpt-5-codex-mini”
2025-11-06
GPT-5-Codex model update
We’ve shipped a minor update to GPT-5-Codex:
More reliable file edits with
apply_patch
.
Fewer destructive actions such as
git reset
.
More collaborative behavior when encountering user edits in files.
3% more efficient in time and usage.
October 2025
2025-10-30
Credits on ChatGPT Pro and Plus
Codex users on ChatGPT Plus and Pro can now use on-demand credits for more Codex usage beyond what’s included in your plan.
Learn more.
2025-10-22
Tag @Codex on GitHub Issues and PRs
You can now tag
@codex
on a teammate’s pull request to ask clarifying questions, request a follow-up, or ask Codex to make changes. GitHub Issues now also support
@codex
mentions, so you can kick off tasks from any issue, without leaving your workflow.
2025-10-06
Codex is now GA
Codex is now generally available with 3 new features — @Codex in Slack, Codex SDK, and new admin tools.
@Codex in Slack
You can now questions and assign tasks to Codex directly from Slack. See the
Slack guide
to get started.
Codex SDK
Integrate the same agent that powers the Codex CLI inside your own tools and workflows with the Codex SDK in Typescript. With the new Codex GitHub Action, you can easily add Codex to CI/CD workflows. See the
Codex SDK guide
to get started.
import
{ Codex }
from
"@openai/codex-sdk"
;
const
agent
=
new
Codex
();
const
thread
=
await
agent.
startThread
();
const
result
=
await
thread.
run
(
"Explore this repo"
);
console.
log
(result);
const
result2
=
await
thread.
run
(
"Propose changes"
);
console.
log
(result2);
New admin controls and analytics
ChatGPT workspace admins can now edit or delete Codex Cloud environments. With managed config files, they can set safe defaults for CLI and IDE usage and monitor how Codex uses commands locally. New analytics dashboards help you track Codex usage and code review feedback. Learn more in the
enterprise admin guide.
Availability and pricing updates
The Slack integration and Codex SDK are available to developers on ChatGPT Plus, Pro, Business, Edu, and Enterprise plans starting today, while the new admin features will be available to Business, Edu, and Enterprise.
Beginning October 20, Codex Cloud tasks will count toward your Codex usage. Review the
Codex pricing guide
for plan-specific details.
September 2025
2025-09-23
GPT-5-Codex in the API
GPT-5-Codex is now available in the Responses API, and you can also use it with your API Key in the Codex CLI.
We plan on regularly updating this model snapshot.
It is available at the same price as GPT-5. You can learn more about pricing and rate limits for this model on our
model page
.
2025-09-15
Introducing GPT-5-Codex
New model: GPT-5-Codex
GPT-5-Codex is a version of GPT-5 further optimized for agentic coding in Codex.
It’s available in the IDE extension and CLI when you sign in with your ChatGPT account.
It also powers the cloud agent and Code Review in GitHub.
To learn more about GPT-5-Codex and how it performs compared to GPT-5 on software engineering tasks, see our
announcement blog post
.
Image outputs
When working in the cloud on front-end engineering tasks, GPT-5-Codex can now display screenshots of the UI in Codex web for you to review. With image output, you can iterate on the design without needing to check out the branch locally.
New in Codex CLI
You can now resume sessions where you left off with
codex resume
.
Context compaction automatically summarizes the session as it approaches the context window limit.
Learn more in the
latest release notes
August 2025
2025-08-27
Late August update
IDE extension (Compatible with VS Code, Cursor, Windsurf)
Codex now runs in your IDE with an interactive UI for fast local iteration. Easily switch between modes and reasoning efforts.
Sign in with ChatGPT (IDE & CLI)
One-click authentication that removes API keys and uses ChatGPT Enterprise credits.
Move work between local ↔ cloud
Hand off tasks to Codex web from the IDE with the ability to apply changes locally so you can delegate jobs without leaving your editor.
Code Reviews
Codex goes beyond static analysis. It checks a PR against its intent, reasons across the codebase and dependencies, and can run code to validate the behavior of changes.
2025-08-21
Mid August update
Image inputs
You can now attach images to your prompts in Codex web. This is great for asking Codex to implement frontend changes or follow up on whiteboarding sessions.
Container caching
Codex now caches containers to start new tasks and followups 90% faster, dropping the median start time from 48 seconds to 5 seconds. You can optionally configure a maintenance script to update the environment from its cached state to prepare for new tasks. See the docs for more.
Automatic environment setup
Now, environments without manual setup scripts automatically run the standard installation commands for common package managers like yarn, pnpm, npm, go mod, gradle, pip, poetry, uv, and cargo. This reduces test failures for new environments by 40%.
June 2025
2025-06-13
Best of N
Codex can now generate multiple responses simultaneously for a single task, helping you quickly explore possible solutions to pick the best approach.
Fixes & improvements
Added some keyboard shortcuts and a page to explore them. Open it by pressing ⌘-/ on macOS and Ctrl+/ on other platforms.
Added a “branch” query parameter in addition to the existing “environment”, “prompt” and “tab=archived” parameters.
Added a loading indicator when downloading a repo during container setup.
Added support for cancelling tasks.
Fixed issues causing tasks to fail during setup.
Fixed issues running followups in environments where the setup script changes files that are gitignored.
Improved how the agent understands and reacts to network access restrictions.
Increased the update rate of text describing what Codex is doing.
Increased the limit for setup script duration to 20 minutes for Pro and Business users.
Polished code diffs: You can now option-click a code diff header to expand/collapse all of them.
2025-06-03
June update
Agent internet access
Now you can give Codex access to the internet during task execution to install dependencies, upgrade packages, run tests that need external resources, and more.
Internet access is off by default. Plus, Pro, and Business users can enable it for specific environments, with granular control of which domains and HTTP methods Codex can access. Internet access for Enterprise users is coming soon.
Learn more about usage and risks in the
docs
.
Update existing PRs
Now you can update existing pull requests when following up on a task.
Voice dictation
Now you can dictate tasks to Codex.
Fixes & improvements
Added a link to this changelog from the profile menu.
Added support for binary files: When applying patches, all file operations are supported. When using PRs, only deleting or renaming binary files is supported for now.
Fixed an issue on iOS where follow up tasks where shown duplicated in the task list.
Fixed an issue on iOS where pull request statuses were out of date.
Fixed an issue with follow ups where the environments were incorrectly started with the state from the first turn, rather than the most recent state.
Fixed internationalization of task events and logs.
Improved error messages for setup scripts.
Increased the limit on task diffs from 1 MB to 5 MB.
Increased the limit for setup script duration from 5 to 10 minutes.
Polished GitHub connection flow.
Re-enabled Live Activities on iOS after resolving an issue with missed notifications.
Removed the mandatory two-factor authentication requirement for users using SSO or social logins.
May 2025
2025-05-22
Reworked environment page
It’s now easier and faster to set up code execution.
Fixes & improvements
Added a button to retry failed tasks
Added indicators to show that the agent runs without network access after setup
Added options to copy git patches after pushing a PR
Added support for unicode branch names
Fixed a bug where secrets were not piped to the setup script
Fixed creating branches when there’s a branch name conflict.
Fixed rendering diffs with multi-character emojis.
Improved error messages when starting tasks, running setup scripts, pushing PRs, or disconnected from GitHub to be more specific and indicate how to resolve the error.
Improved onboarding for teams.
Polished how new tasks look while loading.
Polished the followup composer.
Reduced GitHub disconnects by 90%.
Reduced PR creation latency by 35%.
Reduced tool call latency by 50%.
Reduced task completion latency by 20%.
Started setting page titles to task names so Codex tabs are easier to tell apart.
Tweaked the system prompt so that agent knows it’s working without network, and can suggest that the user set up dependencies.
Updated the docs.
2025-05-19
Codex in the ChatGPT iOS app
Start tasks, view diffs, and push PRs—while you’re away from your desk.
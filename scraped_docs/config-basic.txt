URL: https://developers.openai.com/codex/config-basic
Scraped: 2026-02-27T16:31:24.187892+00:00

Config basics
Search the Codex docs
Primary navigation
Get started
Overview
Quickstart
Models
Pricing
Libraries
Latest: GPT-5.2
Core concepts
Text generation
Code generation
Images and vision
Audio and speech
Structured output
Function calling
Responses API
Agents
Overview
Build agents
Agent Builder
Node reference
Safety in building agents
Agents SDK
Deploy in your product
ChatKit
Custom theming
Widgets
Actions
Advanced integration
Optimize
Agent evals
Trace grading
Voice agents
Tools
Using tools
Connectors and MCP
Skills
Shell
Web search
Code interpreter
File search and retrieval
File search
Retrieval
More tools
Image generation
Computer use
Local shell tool
Apply patch
Run and scale
Conversation state
Background mode
Streaming
WebSocket mode
Webhooks
File inputs
Context management
Compaction
Counting tokens
Prompt caching
Prompting
Overview
Prompt engineering
Reasoning
Reasoning models
Reasoning best practices
Evaluation
Getting started
Working with evals
Prompt optimizer
External models
Best practices
Realtime API
Overview
Connect
WebRTC
WebSocket
SIP
Usage
Using realtime models
Managing conversations
Webhooks and server-side controls
Managing costs
Realtime transcription
Voice agents
Model optimization
Optimization cycle
Fine-tuning
Supervised fine-tuning
Vision fine-tuning
Direct preference optimization
Reinforcement fine-tuning
RFT use cases
Best practices
Graders
Specialized models
Image generation
Video generation
Text to speech
Speech to text
Deep research
Embeddings
Moderation
Going live
Production best practices
Latency optimization
Overview
Predicted Outputs
Priority processing
Cost optimization
Overview
Batch
Flex processing
Accuracy optimization
Safety
Safety best practices
Safety checks
Cybersecurity checks
Under 18 API Guidance
Legacy APIs
Assistants API
Migration guide
Deep dive
Tools
Resources
Terms and policies
Changelog
Your data
Permissions
Rate limits
Deprecations
MCP for deep research
Developer mode
ChatGPT Actions
Introduction
Getting started
Actions library
Authentication
Production
Data retrieval
Sending files
Getting Started
Overview
Quickstart
Explore
Pricing
Concepts
Prompting
Customization
Multi-agents
Workflows
Models
Cyber Safety
Using Codex
App
Overview
Features
Settings
Review
Automations
Worktrees
Local Environments
Commands
Troubleshooting
IDE Extension
Overview
Features
Settings
IDE Commands
Slash commands
CLI
Overview
Features
Command Line Options
Slash commands
Web
Overview
Environments
Internet Access
Integrations
GitHub
Slack
Linear
Configuration
Config File
Config Basics
Advanced Config
Config Reference
Sample Config
Rules
AGENTS.md
MCP
Skills
Multi-agents
Administration
Authentication
Security
Enterprise
Admin Setup
Governance
Managed configuration
Windows
Automation
Non-interactive Mode
Codex SDK
App Server
MCP Server
GitHub Action
Learn
Videos
Blog
Building frontend UIs with Codex and Figma
Testing Agent Skills Systematically with Evals
View all
Cookbooks
Codex Prompting Guide
Long horizon tasks with Codex
View all
Building AI Teams
Community
Ambassadors
Meetups
Releases
Changelog
Feature Maturity
Open Source
Home
Quickstart
Core Concepts
MCP Apps in ChatGPT
MCP Server
UX principles
UI guidelines
Plan
Research use cases
Define tools
Design components
Build
Set up your server
Build your ChatGPT UI
Authenticate users
Manage state
Monetize your app
Examples
Deploy
Deploy your app
Connect from ChatGPT
Test your integration
Submit your app
Guides
Optimize Metadata
Security & Privacy
Troubleshooting
Resources
Changelog
App submission guidelines
Reference
Home
Guides
Get started
Key concepts
Production readiness
Commerce specs
Agentic Checkout
Delegated Payment
Product feeds
Overview
Onboarding
Feed spec
Best practices
Home
Docs MCP
Categories
Code
Cookbooks
Guides
Videos
Topics
Agents
Audio & Voice
Computer use
Codex
Evals
gpt-oss
Fine-tuning
Image generation
Scaling
Tools
Video generation
Home
Topics
Agents
Evals
Multimodal
Text
Guardrails
Optimization
ChatGPT
Codex
gpt-oss
Contribute
Cookbook on GitHub
All posts
Recent
Building frontend UIs with Codex and Figma
Shell + Skills + Compaction: Tips for long-running agents that do real work
15 lessons learned building ChatGPT Apps
Testing Agent Skills Systematically with Evals
Supercharging Codex with JetBrains MCP at Skyscanner
Topics
General
API
Apps SDK
Audio
Codex
API Dashboard
Codex reads configuration details from more than one location. Your personal defaults live in
~/.codex/config.toml
, and you can add project overrides with
.codex/config.toml
files. For security, Codex loads project config files only when you trust the project.
Codex configuration file
Codex stores user-level configuration at
~/.codex/config.toml
. To scope settings to a specific project or subfolder, add a
.codex/config.toml
file in your repo.
To open the configuration file from the Codex IDE extension, select the gear icon in the top-right corner, then select
Codex Settings > Open config.toml
.
The CLI and IDE extension share the same configuration layers. You can use them to:
Set the default model and provider.
Configure
approval policies and sandbox settings
.
Configure
MCP servers
.
Configuration precedence
Codex resolves values in this order (highest precedence first):
CLI flags and
--config
overrides
Profile
values (from
--profile <name>
)
Project config files:
.codex/config.toml
, ordered from the project root down to your current working directory (closest wins; trusted projects only)
User config:
~/.codex/config.toml
System config (if present):
/etc/codex/config.toml
on Unix
Built-in defaults
Use that precedence to set shared defaults at the top level and keep profiles focused on the values that differ.
If you mark a project as untrusted, Codex skips project-scoped
.codex/
layers (including
.codex/config.toml
) and falls back to user, system, and built-in defaults.
For one-off overrides via
-c
/
--config
(including TOML quoting rules), see
Advanced Config
.
On managed machines, your organization may also enforce constraints via
requirements.toml
(for example, disallowing
approval_policy = "never"
or
sandbox_mode = "danger-full-access"
). See
Managed
configuration
and
Admin-enforced
requirements
.
Common configuration options
Here are a few options people change most often:
Default model
Choose the model Codex uses by default in the CLI and IDE.
model =
"gpt-5.2"
Approval prompts
Control when Codex pauses to ask before running generated commands.
approval_policy =
"on-request"
For behavior differences between
untrusted
,
on-request
, and
never
, see
Run without approval prompts
and
Common sandbox and approval combinations
.
Sandbox level
Adjust how much filesystem and network access Codex has while executing commands.
sandbox_mode =
"workspace-write"
For mode-by-mode behavior (including protected
.git
/
.codex
paths and network defaults), see
Sandbox and approvals
,
Protected paths in writable roots
, and
Network access
.
Windows sandbox mode
When running Codex natively on Windows, set the native sandbox mode to
elevated
in the
windows
table. Use
unelevated
only if you do not have administrator permissions or if elevated setup fails.
[
windows
]
sandbox =
"elevated"
# Recommended
# sandbox = "unelevated" # Fallback if admin permissions/setup are unavailable
Web search mode
Codex enables web search by default for local tasks and serves results from a web search cache. The cache is an OpenAI-maintained index of web results, so cached mode returns pre-indexed results instead of fetching live pages. This reduces exposure to prompt injection from arbitrary live content, but you should still treat web results as untrusted. If you are using
--yolo
or another
full access sandbox setting
, web search defaults to live results. Choose a mode with
web_search
:
"cached"
(default) serves results from the web search cache.
"live"
fetches the most recent data from the web (same as
--search
).
"disabled"
turns off the web search tool.
web_search =
"cached"
# default; serves results from the web search cache
# web_search = "live"  # fetch the most recent data from the web (same as --search)
# web_search = "disabled"
Reasoning effort
Tune how much reasoning effort the model applies when supported.
model_reasoning_effort =
"high"
Communication style
Set a default communication style for supported models.
personality =
"friendly"
# or "pragmatic" or "none"
You can override this later in an active session with
/personality
or per thread/turn when using the app-server APIs.
Command environment
Control which environment variables Codex forwards to spawned commands.
[
shell_environment_policy
]
include_only = [
"PATH"
,
"HOME"
]
Log directory
Override where Codex writes local log files such as
codex-tui.log
.
log_dir =
"/absolute/path/to/codex-logs"
For one-off runs, you can also set it from the CLI:
codex
-c
log_dir=./.codex-log
Feature flags
Use the
[features]
table in
config.toml
to toggle optional and experimental capabilities.
[
features
]
shell_snapshot =
true
# Speed up repeated commands
Supported features
Key
Default
Maturity
Description
apply_patch_freeform
false
Experimental
Include the freeform
apply_patch
tool
apps
false
Experimental
Enable ChatGPT Apps/connectors support
apps_mcp_gateway
false
Experimental
Route Apps MCP calls through
https://api.openai.com/v1/connectors/mcp/
instead of legacy routing
collaboration_modes
true
Stable
Enable collaboration modes such as plan mode
multi_agent
false
Experimental
Enable multi-agent collaboration tools
personality
true
Stable
Enable personality selection controls
remote_models
false
Experimental
Refresh remote model list before showing readiness
runtime_metrics
false
Experimental
Show runtime metrics summaries in TUI turn separators
request_rule
true
Stable
Enable Smart approvals (
prefix_rule
suggestions)
search_tool
false
Experimental
Enable
search_tool_bm25
so Codex discovers Apps MCP tools via search before tool calls
shell_snapshot
false
Beta
Snapshot your shell environment to speed up repeated commands
shell_tool
true
Stable
Enable the default
shell
tool
use_linux_sandbox_bwrap
false
Experimental
Use the bubblewrap-based Linux sandbox pipeline
unified_exec
false
Beta
Use the unified PTY-backed exec tool
undo
true
Stable
Enable undo via per-turn git ghost snapshots
web_search
true
Deprecated
Legacy toggle; prefer the top-level
web_search
setting
web_search_cached
true
Deprecated
Legacy toggle that maps to
web_search = "cached"
when unset
web_search_request
true
Deprecated
Legacy toggle that maps to
web_search = "live"
when unset
The Maturity column uses feature maturity labels such as Experimental, Beta,
and Stable. See
Feature Maturity
for how to
interpret these labels.
Omit feature keys to keep their defaults.
Enabling features
In
config.toml
, add
feature_name = true
under
[features]
.
From the CLI, run
codex --enable feature_name
.
To enable more than one feature, run
codex --enable feature_a --enable feature_b
.
To disable a feature, set the key to
false
in
config.toml
.
URL: https://developers.openai.com/codex/enterprise/managed-configuration
Scraped: 2026-02-27T16:31:36.815637+00:00

Managed configuration
Search the Codex docs
Primary navigation
Get started
Overview
Quickstart
Models
Pricing
Libraries
Latest: GPT-5.2
Core concepts
Text generation
Code generation
Images and vision
Audio and speech
Structured output
Function calling
Responses API
Agents
Overview
Build agents
Agent Builder
Node reference
Safety in building agents
Agents SDK
Deploy in your product
ChatKit
Custom theming
Widgets
Actions
Advanced integration
Optimize
Agent evals
Trace grading
Voice agents
Tools
Using tools
Connectors and MCP
Skills
Shell
Web search
Code interpreter
File search and retrieval
File search
Retrieval
More tools
Image generation
Computer use
Local shell tool
Apply patch
Run and scale
Conversation state
Background mode
Streaming
WebSocket mode
Webhooks
File inputs
Context management
Compaction
Counting tokens
Prompt caching
Prompting
Overview
Prompt engineering
Reasoning
Reasoning models
Reasoning best practices
Evaluation
Getting started
Working with evals
Prompt optimizer
External models
Best practices
Realtime API
Overview
Connect
WebRTC
WebSocket
SIP
Usage
Using realtime models
Managing conversations
Webhooks and server-side controls
Managing costs
Realtime transcription
Voice agents
Model optimization
Optimization cycle
Fine-tuning
Supervised fine-tuning
Vision fine-tuning
Direct preference optimization
Reinforcement fine-tuning
RFT use cases
Best practices
Graders
Specialized models
Image generation
Video generation
Text to speech
Speech to text
Deep research
Embeddings
Moderation
Going live
Production best practices
Latency optimization
Overview
Predicted Outputs
Priority processing
Cost optimization
Overview
Batch
Flex processing
Accuracy optimization
Safety
Safety best practices
Safety checks
Cybersecurity checks
Under 18 API Guidance
Legacy APIs
Assistants API
Migration guide
Deep dive
Tools
Resources
Terms and policies
Changelog
Your data
Permissions
Rate limits
Deprecations
MCP for deep research
Developer mode
ChatGPT Actions
Introduction
Getting started
Actions library
Authentication
Production
Data retrieval
Sending files
Getting Started
Overview
Quickstart
Explore
Pricing
Concepts
Prompting
Customization
Multi-agents
Workflows
Models
Cyber Safety
Using Codex
App
Overview
Features
Settings
Review
Automations
Worktrees
Local Environments
Commands
Troubleshooting
IDE Extension
Overview
Features
Settings
IDE Commands
Slash commands
CLI
Overview
Features
Command Line Options
Slash commands
Web
Overview
Environments
Internet Access
Integrations
GitHub
Slack
Linear
Configuration
Config File
Config Basics
Advanced Config
Config Reference
Sample Config
Rules
AGENTS.md
MCP
Skills
Multi-agents
Administration
Authentication
Security
Enterprise
Admin Setup
Governance
Managed configuration
Windows
Automation
Non-interactive Mode
Codex SDK
App Server
MCP Server
GitHub Action
Learn
Videos
Blog
Building frontend UIs with Codex and Figma
Testing Agent Skills Systematically with Evals
View all
Cookbooks
Codex Prompting Guide
Long horizon tasks with Codex
View all
Building AI Teams
Community
Ambassadors
Meetups
Releases
Changelog
Feature Maturity
Open Source
Home
Quickstart
Core Concepts
MCP Apps in ChatGPT
MCP Server
UX principles
UI guidelines
Plan
Research use cases
Define tools
Design components
Build
Set up your server
Build your ChatGPT UI
Authenticate users
Manage state
Monetize your app
Examples
Deploy
Deploy your app
Connect from ChatGPT
Test your integration
Submit your app
Guides
Optimize Metadata
Security & Privacy
Troubleshooting
Resources
Changelog
App submission guidelines
Reference
Home
Guides
Get started
Key concepts
Production readiness
Commerce specs
Agentic Checkout
Delegated Payment
Product feeds
Overview
Onboarding
Feed spec
Best practices
Home
Docs MCP
Categories
Code
Cookbooks
Guides
Videos
Topics
Agents
Audio & Voice
Computer use
Codex
Evals
gpt-oss
Fine-tuning
Image generation
Scaling
Tools
Video generation
Home
Topics
Agents
Evals
Multimodal
Text
Guardrails
Optimization
ChatGPT
Codex
gpt-oss
Contribute
Cookbook on GitHub
All posts
Recent
Building frontend UIs with Codex and Figma
Shell + Skills + Compaction: Tips for long-running agents that do real work
15 lessons learned building ChatGPT Apps
Testing Agent Skills Systematically with Evals
Supercharging Codex with JetBrains MCP at Skyscanner
Topics
General
API
Apps SDK
Audio
Codex
API Dashboard
Enterprise admins can control local Codex behavior in two ways:
Requirements
: admin-enforced constraints that users can’t override.
Managed defaults
: starting values applied when Codex launches. Users can still change settings during a session; Codex reapplies managed defaults the next time it starts.
Admin-enforced requirements (requirements.toml)
Requirements constrain security-sensitive settings (approval policy, sandbox mode, web search mode, and optionally which MCP servers can be enabled). When resolving configuration (for example from
config.toml
, profiles, or CLI config overrides), if a value conflicts with an enforced requirement, Codex falls back to a requirements-compatible value and notifies the user. If an
mcp_servers
allowlist is configured, Codex enables an MCP server only when both its name and identity match an approved entry; otherwise, Codex disables it.
For the exact key list, see the
requirements.toml
section in Configuration Reference
.
Locations and precedence
Requirements layers are applied in this order (earlier wins per field):
Cloud-managed requirements (ChatGPT Business or Enterprise)
macOS managed preferences (MDM) via
com.openai.codex:requirements_toml_base64
System
requirements.toml
(
/etc/codex/requirements.toml
on Unix systems, including Linux/macOS)
Across layers, requirements are merged per field: if an earlier layer sets a field (including an empty list), later layers do not override that field, but lower layers can still fill fields that remain unset.
For backwards compatibility, Codex also interprets legacy
managed_config.toml
fields
approval_policy
and
sandbox_mode
as requirements (allowing only that single value).
Cloud-managed requirements
When you sign in with ChatGPT on a Business or Enterprise plan, Codex can also fetch admin-enforced requirements from the Codex service. This is another source of
requirements.toml
-compatible requirements. This applies across Codex surfaces, including the CLI, App, and IDE Extension.
Configure cloud-managed requirements
Go to the
Codex managed-config page
.
Create a new managed requirements file using the same format and keys as
requirements.toml
.
enforce_residency =
"us"
allowed_approval_policies = [
"on-request"
]
allowed_sandbox_modes = [
"read-only"
,
"workspace-write"
]
[
rules
]
prefix_rules = [
{ pattern = [{ any_of = [
"bash"
,
"sh"
,
"zsh"
] }], decision =
"prompt"
, justification =
"Require explicit approval for shell entrypoints"
},
]
Save the configuration. Once saved, the updated managed requirements apply immediately for matching users.
For more examples, see
Example requirements.toml
.
Assign requirements to groups
Admins can configure different managed requirements for different user groups, and also set a default fallback requirements policy.
If a user matches multiple group-specific rules, the first matching rule applies. Codex does not fill unset requirement fields from later matching group rules.
For example, if the first matching group rule sets only
allowed_sandbox_modes = ["read-only"]
and a later matching group rule sets
allowed_approval_policies = ["on-request"]
, Codex applies only the first matching group rule and does not fill
allowed_approval_policies
from the later rule.
How Codex applies cloud-managed requirements locally
When a user starts Codex and signs in with ChatGPT on a Business or Enterprise plan, Codex applies managed requirements on a best-effort basis. Codex first checks for a valid, unexpired local managed requirements cache entry and uses it if available. If the cache is missing, expired, invalid, or does not match the current auth identity, Codex attempts to fetch managed requirements from the service (with retries) and writes a new signed cache entry on success. If no valid cached entry is available and the fetch fails or times out, Codex continues without the managed requirements layer.
After cache resolution, managed requirements are enforced as part of the normal requirements layering described above.
Example requirements.toml
This example blocks
--ask-for-approval never
and
--sandbox danger-full-access
(including
--yolo
):
allowed_approval_policies = [
"untrusted"
,
"on-request"
]
allowed_sandbox_modes = [
"read-only"
,
"workspace-write"
]
You can also constrain web search mode:
allowed_web_search_modes = [
"cached"
]
# "disabled" remains implicitly allowed
allowed_web_search_modes = []
effectively allows only
"disabled"
.
For example,
allowed_web_search_modes = ["cached"]
prevents live web search even in
danger-full-access
sessions.
Enforce command rules from requirements
Admins can also enforce restrictive command rules from
requirements.toml
using a
[rules]
table. These rules merge with regular
.rules
files, and the
most restrictive decision still wins.
Unlike
.rules
, requirements rules must specify
decision
, and that decision
must be
"prompt"
or
"forbidden"
(not
"allow"
).
[
rules
]
prefix_rules = [
{ pattern = [{ token =
"rm"
}], decision =
"forbidden"
, justification =
"Use git clean -fd instead."
},
{ pattern = [{ token =
"git"
}, { any_of = [
"push"
,
"commit"
] }], decision =
"prompt"
, justification =
"Require review before mutating history."
},
]
To restrict which MCP servers Codex can enable, add an
mcp_servers
approved list. For stdio servers, match on
command
; for streamable HTTP servers, match on
url
:
[
mcp_servers
.
docs
]
identity = { command =
"codex-mcp"
}
[
mcp_servers
.
remote
]
identity = { url =
"https://example.com/mcp"
}
If
mcp_servers
is present but empty, Codex disables all MCP servers.
Managed defaults (
managed_config.toml
)
Managed defaults merge on top of a user’s local
config.toml
and take precedence over any CLI
--config
overrides, setting the starting values when Codex launches. Users can still change those settings during a session; Codex reapplies managed defaults the next time it starts.
Make sure your managed defaults meet your requirements; Codex rejects disallowed values.
Precedence and layering
Codex assembles the effective configuration in this order (top overrides bottom):
Managed preferences (macOS MDM; highest precedence)
managed_config.toml
(system/managed file)
config.toml
(user’s base configuration)
CLI
--config key=value
overrides apply to the base, but managed layers override them. This means each run starts from the managed defaults even if you provide local flags.
Cloud-managed requirements affect the requirements layer (not managed defaults). See the Admin-enforced requirements section above for precedence.
Locations
Linux/macOS (Unix):
/etc/codex/managed_config.toml
Windows/non-Unix:
~/.codex/managed_config.toml
If the file is missing, Codex skips the managed layer.
macOS managed preferences (MDM)
On macOS, admins can push a device profile that provides base64-encoded TOML payloads at:
Preference domain:
com.openai.codex
Keys:
config_toml_base64
(managed defaults)
requirements_toml_base64
(requirements)
Codex parses these “managed preferences” payloads as TOML. For managed defaults (
config_toml_base64
), managed preferences have the highest precedence. For requirements (
requirements_toml_base64
), precedence follows the cloud-managed requirements order described above.
MDM setup workflow
Codex honors standard macOS MDM payloads, so you can distribute settings with tooling like
Jamf Pro
,
Fleet
, or
Kandji
. A lightweight deployment looks like:
Build the managed payload TOML and encode it with
base64
(no wrapping).
Drop the string into your MDM profile under the
com.openai.codex
domain at
config_toml_base64
(managed defaults) or
requirements_toml_base64
(requirements).
Push the profile, then ask users to restart Codex and confirm the startup config summary reflects the managed values.
When revoking or changing policy, update the managed payload; the CLI reads the refreshed preference the next time it launches.
Avoid embedding secrets or high-churn dynamic values in the payload. Treat the managed TOML like any other MDM setting under change control.
Example managed_config.toml
# Set conservative defaults
approval_policy =
"on-request"
sandbox_mode    =
"workspace-write"
[
sandbox_workspace_write
]
network_access =
false
# keep network disabled unless explicitly allowed
[
otel
]
environment =
"prod"
exporter =
"otlp-http"
# point at your collector
log_user_prompt =
false
# keep prompts redacted
# exporter details live under exporter tables; see Monitoring and telemetry above
Recommended guardrails
Prefer
workspace-write
with approvals for most users; reserve full access for controlled containers.
Keep
network_access = false
unless your security review allows a collector or domains required by your workflows.
Use managed configuration to pin OTel settings (exporter, environment), but keep
log_user_prompt = false
unless your policy explicitly allows storing prompt contents.
Periodically audit diffs between local
config.toml
and managed policy to catch drift; managed layers should win over local flags and files.
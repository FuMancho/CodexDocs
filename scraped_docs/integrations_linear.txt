URL: https://developers.openai.com/codex/integrations/linear
Scraped: 2026-02-27T16:31:23.633240+00:00

Use Codex in Linear
Search the Codex docs
Primary navigation
Get started
Overview
Quickstart
Models
Pricing
Libraries
Latest: GPT-5.2
Core concepts
Text generation
Code generation
Images and vision
Audio and speech
Structured output
Function calling
Responses API
Agents
Overview
Build agents
Agent Builder
Node reference
Safety in building agents
Agents SDK
Deploy in your product
ChatKit
Custom theming
Widgets
Actions
Advanced integration
Optimize
Agent evals
Trace grading
Voice agents
Tools
Using tools
Connectors and MCP
Skills
Shell
Web search
Code interpreter
File search and retrieval
File search
Retrieval
More tools
Image generation
Computer use
Local shell tool
Apply patch
Run and scale
Conversation state
Background mode
Streaming
WebSocket mode
Webhooks
File inputs
Context management
Compaction
Counting tokens
Prompt caching
Prompting
Overview
Prompt engineering
Reasoning
Reasoning models
Reasoning best practices
Evaluation
Getting started
Working with evals
Prompt optimizer
External models
Best practices
Realtime API
Overview
Connect
WebRTC
WebSocket
SIP
Usage
Using realtime models
Managing conversations
Webhooks and server-side controls
Managing costs
Realtime transcription
Voice agents
Model optimization
Optimization cycle
Fine-tuning
Supervised fine-tuning
Vision fine-tuning
Direct preference optimization
Reinforcement fine-tuning
RFT use cases
Best practices
Graders
Specialized models
Image generation
Video generation
Text to speech
Speech to text
Deep research
Embeddings
Moderation
Going live
Production best practices
Latency optimization
Overview
Predicted Outputs
Priority processing
Cost optimization
Overview
Batch
Flex processing
Accuracy optimization
Safety
Safety best practices
Safety checks
Cybersecurity checks
Under 18 API Guidance
Legacy APIs
Assistants API
Migration guide
Deep dive
Tools
Resources
Terms and policies
Changelog
Your data
Permissions
Rate limits
Deprecations
MCP for deep research
Developer mode
ChatGPT Actions
Introduction
Getting started
Actions library
Authentication
Production
Data retrieval
Sending files
Getting Started
Overview
Quickstart
Explore
Pricing
Concepts
Prompting
Customization
Multi-agents
Workflows
Models
Cyber Safety
Using Codex
App
Overview
Features
Settings
Review
Automations
Worktrees
Local Environments
Commands
Troubleshooting
IDE Extension
Overview
Features
Settings
IDE Commands
Slash commands
CLI
Overview
Features
Command Line Options
Slash commands
Web
Overview
Environments
Internet Access
Integrations
GitHub
Slack
Linear
Configuration
Config File
Config Basics
Advanced Config
Config Reference
Sample Config
Rules
AGENTS.md
MCP
Skills
Multi-agents
Administration
Authentication
Security
Enterprise
Admin Setup
Governance
Managed configuration
Windows
Automation
Non-interactive Mode
Codex SDK
App Server
MCP Server
GitHub Action
Learn
Videos
Blog
Building frontend UIs with Codex and Figma
Testing Agent Skills Systematically with Evals
View all
Cookbooks
Codex Prompting Guide
Long horizon tasks with Codex
View all
Building AI Teams
Community
Ambassadors
Meetups
Releases
Changelog
Feature Maturity
Open Source
Home
Quickstart
Core Concepts
MCP Apps in ChatGPT
MCP Server
UX principles
UI guidelines
Plan
Research use cases
Define tools
Design components
Build
Set up your server
Build your ChatGPT UI
Authenticate users
Manage state
Monetize your app
Examples
Deploy
Deploy your app
Connect from ChatGPT
Test your integration
Submit your app
Guides
Optimize Metadata
Security & Privacy
Troubleshooting
Resources
Changelog
App submission guidelines
Reference
Home
Guides
Get started
Key concepts
Production readiness
Commerce specs
Agentic Checkout
Delegated Payment
Product feeds
Overview
Onboarding
Feed spec
Best practices
Home
Docs MCP
Categories
Code
Cookbooks
Guides
Videos
Topics
Agents
Audio & Voice
Computer use
Codex
Evals
gpt-oss
Fine-tuning
Image generation
Scaling
Tools
Video generation
Home
Topics
Agents
Evals
Multimodal
Text
Guardrails
Optimization
ChatGPT
Codex
gpt-oss
Contribute
Cookbook on GitHub
All posts
Recent
Building frontend UIs with Codex and Figma
Shell + Skills + Compaction: Tips for long-running agents that do real work
15 lessons learned building ChatGPT Apps
Testing Agent Skills Systematically with Evals
Supercharging Codex with JetBrains MCP at Skyscanner
Topics
General
API
Apps SDK
Audio
Codex
API Dashboard
Use Codex in Linear to delegate work from issues. Assign an issue to Codex or mention
@Codex
in a comment, and Codex creates a cloud task and replies with progress and results.
Codex in Linear is available on paid plans (see
Pricing
).
If you’re on an Enterprise plan, ask your ChatGPT workspace admin to turn on Codex cloud tasks in
workspace settings
and enable
Codex for Linear
in
connector settings
.
Set up the Linear integration
Set up
Codex cloud tasks
by connecting GitHub in
Codex
and creating an
environment
for the repository you want Codex to work in.
Go to
Codex settings
and install
Codex for Linear
for your workspace.
Link your Linear account by mentioning
@Codex
in a comment thread on a Linear issue.
Delegate work to Codex
You can delegate in two ways:
Assign an issue to Codex
After you install the integration, you can assign issues to Codex the same way you assign them to teammates. Codex starts work and posts updates back to the issue.
Mention
@Codex
in comments
You can also mention
@Codex
in comment threads to delegate work or ask questions. After Codex replies, follow up in the thread to continue the same session.
After Codex starts working on an issue, it
chooses an environment and repo
to work in.
To pin a specific repo, include it in your comment, for example:
@Codex fix this in openai/codex
.
To track progress:
Open
Activity
on the issue to see progress updates.
Open the task link to follow along in more detail.
When the task finishes, Codex posts a summary and a link to the completed task so you can create a pull request.
How Codex chooses an environment and repo
Linear suggests a repository based on the issue context. Codex selects the environment that best matches that suggestion. If the request is ambiguous, it falls back to the environment you used most recently.
The task runs against the default branch of the first repository listed in that environment’s repo map. Update the repo map in Codex if you need a different default or more repositories.
If no suitable environment or repository is available, Codex will reply in Linear with instructions on how to fix the issue before retrying.
Automatically assign issues to Codex
You can assign issues to Codex automatically using triage rules:
In Linear, go to
Settings
.
Under
Your teams
, select your team.
In the workflow settings, open
Triage
and turn it on.
In
Triage rules
, create a rule and choose
Delegate
>
Codex
(and any other properties you want to set).
Linear assigns new issues that enter triage to Codex automatically.
When you use triage rules, Codex runs tasks using the account of the issue creator.
Data usage, privacy, and security
When you mention
@Codex
or assign an issue to it, Codex receives your issue content to understand your request and create a task.
Data handling follows OpenAI’s
Privacy Policy
,
Terms of Use
, and other applicable
policies
.
For more on security, see the
Codex security documentation
.
Codex uses large language models that can make mistakes. Always review answers and diffs.
Tips and troubleshooting
Missing connections
: If Codex can’t confirm your Linear connection, it replies in the issue with a link to connect your account.
Unexpected environment choice
: Reply in the thread with the environment you want (for example,
@Codex please run this in openai/codex
).
Wrong part of the code
: Add more context in the issue, or give explicit instructions in your
@Codex
comment.
More help
: See the
OpenAI Help Center
.
Connect Linear for local tasks (MCP)
If you’re using the Codex app, CLI, or IDE Extension and want Codex to access Linear issues locally, configure Codex to use the Linear Model Context Protocol (MCP) server.
To learn more,
check out the Linear MCP docs
.
The setup steps for the MCP server are the same regardless of whether you use the IDE extension or the CLI since both share the same configuration.
Use the CLI (recommended)
If you have the CLI installed, run:
codex
mcp
add
linear
--url
https://mcp.linear.app/mcp
This prompts you to sign in with your Linear account and connect it to Codex.
Configure manually
Open
~/.codex/config.toml
in your editor.
Add the following:
[
mcp_servers
.
linear
]
url =
"https://mcp.linear.app/mcp"
Run
codex mcp login linear
to log in.
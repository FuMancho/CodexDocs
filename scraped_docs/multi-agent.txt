URL: https://developers.openai.com/codex/multi-agent
Scraped: 2026-02-27T16:31:30.286086+00:00

Multi-agents
Search the Codex docs
Primary navigation
Get started
Overview
Quickstart
Models
Pricing
Libraries
Latest: GPT-5.2
Core concepts
Text generation
Code generation
Images and vision
Audio and speech
Structured output
Function calling
Responses API
Agents
Overview
Build agents
Agent Builder
Node reference
Safety in building agents
Agents SDK
Deploy in your product
ChatKit
Custom theming
Widgets
Actions
Advanced integration
Optimize
Agent evals
Trace grading
Voice agents
Tools
Using tools
Connectors and MCP
Skills
Shell
Web search
Code interpreter
File search and retrieval
File search
Retrieval
More tools
Image generation
Computer use
Local shell tool
Apply patch
Run and scale
Conversation state
Background mode
Streaming
WebSocket mode
Webhooks
File inputs
Context management
Compaction
Counting tokens
Prompt caching
Prompting
Overview
Prompt engineering
Reasoning
Reasoning models
Reasoning best practices
Evaluation
Getting started
Working with evals
Prompt optimizer
External models
Best practices
Realtime API
Overview
Connect
WebRTC
WebSocket
SIP
Usage
Using realtime models
Managing conversations
Webhooks and server-side controls
Managing costs
Realtime transcription
Voice agents
Model optimization
Optimization cycle
Fine-tuning
Supervised fine-tuning
Vision fine-tuning
Direct preference optimization
Reinforcement fine-tuning
RFT use cases
Best practices
Graders
Specialized models
Image generation
Video generation
Text to speech
Speech to text
Deep research
Embeddings
Moderation
Going live
Production best practices
Latency optimization
Overview
Predicted Outputs
Priority processing
Cost optimization
Overview
Batch
Flex processing
Accuracy optimization
Safety
Safety best practices
Safety checks
Cybersecurity checks
Under 18 API Guidance
Legacy APIs
Assistants API
Migration guide
Deep dive
Tools
Resources
Terms and policies
Changelog
Your data
Permissions
Rate limits
Deprecations
MCP for deep research
Developer mode
ChatGPT Actions
Introduction
Getting started
Actions library
Authentication
Production
Data retrieval
Sending files
Getting Started
Overview
Quickstart
Explore
Pricing
Concepts
Prompting
Customization
Multi-agents
Workflows
Models
Cyber Safety
Using Codex
App
Overview
Features
Settings
Review
Automations
Worktrees
Local Environments
Commands
Troubleshooting
IDE Extension
Overview
Features
Settings
IDE Commands
Slash commands
CLI
Overview
Features
Command Line Options
Slash commands
Web
Overview
Environments
Internet Access
Integrations
GitHub
Slack
Linear
Configuration
Config File
Config Basics
Advanced Config
Config Reference
Sample Config
Rules
AGENTS.md
MCP
Skills
Multi-agents
Administration
Authentication
Security
Enterprise
Admin Setup
Governance
Managed configuration
Windows
Automation
Non-interactive Mode
Codex SDK
App Server
MCP Server
GitHub Action
Learn
Videos
Blog
Building frontend UIs with Codex and Figma
Testing Agent Skills Systematically with Evals
View all
Cookbooks
Codex Prompting Guide
Long horizon tasks with Codex
View all
Building AI Teams
Community
Ambassadors
Meetups
Releases
Changelog
Feature Maturity
Open Source
Home
Quickstart
Core Concepts
MCP Apps in ChatGPT
MCP Server
UX principles
UI guidelines
Plan
Research use cases
Define tools
Design components
Build
Set up your server
Build your ChatGPT UI
Authenticate users
Manage state
Monetize your app
Examples
Deploy
Deploy your app
Connect from ChatGPT
Test your integration
Submit your app
Guides
Optimize Metadata
Security & Privacy
Troubleshooting
Resources
Changelog
App submission guidelines
Reference
Home
Guides
Get started
Key concepts
Production readiness
Commerce specs
Agentic Checkout
Delegated Payment
Product feeds
Overview
Onboarding
Feed spec
Best practices
Home
Docs MCP
Categories
Code
Cookbooks
Guides
Videos
Topics
Agents
Audio & Voice
Computer use
Codex
Evals
gpt-oss
Fine-tuning
Image generation
Scaling
Tools
Video generation
Home
Topics
Agents
Evals
Multimodal
Text
Guardrails
Optimization
ChatGPT
Codex
gpt-oss
Contribute
Cookbook on GitHub
All posts
Recent
Building frontend UIs with Codex and Figma
Shell + Skills + Compaction: Tips for long-running agents that do real work
15 lessons learned building ChatGPT Apps
Testing Agent Skills Systematically with Evals
Supercharging Codex with JetBrains MCP at Skyscanner
Topics
General
API
Apps SDK
Audio
Codex
API Dashboard
Codex can run multi-agent workflows by spawning specialized agents in parallel and then collecting their results in one response. This can be particularly helpful for complex tasks that are highly parallel, such as codebase exploration or implementing a multi-step feature plan.
With multi-agent workflows you can also define your own set of agents with different model configurations and instructions depending on the agent.
For the concepts and tradeoffs behind multi-agent workflows (including context pollution/context rot and model-selection guidance), see
Multi-agents concepts
.
Enable multi-agent
Multi-agent workflows are currently experimental and need to be explicitly enabled.
You can enable this feature from the CLI with
/experimental
. Enable
Multi-agents
, then restart Codex.
Multi-agent activity is currently surfaced in the CLI. Visibility in other
surfaces (the Codex app and IDE Extension) is coming soon.
You can also add the
multi_agent
feature flag
directly to your configuration file (
~/.codex/config.toml
):
[
features
]
multi_agent =
true
Typical workflow
Codex handles orchestration across agents, including spawning new sub-agents, routing follow-up instructions, waiting for results, and closing agent threads.
When many agents are running, Codex waits until all requested results are available, then returns a consolidated response.
Codex will automatically decide when to spawn a new agent or you can explicitly ask it to do so.
For long-running commands or polling workflows, Codex can also use the built-in
monitor
role, which is tuned for waiting and repeated status checks.
To see it in action, try the following prompt on your project:
I would like to review the following points on the current PR (this branch vs main). Spawn one agent per point, wait for all of them, and summarize the result for each point.
1. Security issue
2. Code quality
3. Bugs
4. Race
5. Test flakiness
6. Maintainability of the code
Managing sub-agents
Use
/agent
in the CLI to switch between active agent threads and inspect the ongoing thread.
Ask Codex directly to steer a running sub-agent, stop it, or close completed agent threads.
The
wait
tool supports long polling windows for monitoring workflows (up to 1 hour per call).
Approvals and sandbox controls
Sub-agents inherit your current sandbox policy, but they run with
non-interactive approvals. If a sub-agent attempts an action that would require
a new approval, that action fails and the error is surfaced in the parent
workflow.
You can also override the sandbox configuration for individual
agent roles
such as explicitly marking an agent to work in read-only mode.
Agent roles
You configure agent roles in the
[agents]
section of your
configuration
.
Agent roles can be defined either in your local configuration (typically
~/.codex/config.toml
) or shared in a project-specific
.codex/config.toml
.
Each role can provide guidance (
description
) for when Codex should use this agent, and optionally load a
role-specific config file (
config_file
) when Codex spawns an agent with that role.
Codex ships with built-in roles:
default
: general-purpose fallback role.
worker
: execution-focused role for implementation and fixes.
explorer
: read-heavy codebase exploration role.
monitor
: long-running command/task monitoring role (optimized for waiting/polling).
Each agent role can override your default configuration. Common settings to override for an agent role are:
model
and
model_reasoning_effort
to select a specific model for your agent role
sandbox_mode
to mark an agent as
read-only
developer_instructions
to give the agent role additional instructions without relying on the parent agent for passing them
Schema
Field
Type
Required
Purpose
agents.max_threads
number
No
Maximum number of concurrently open agent threads.
agents.max_depth
number
No
Maximum nesting depth for spawned agent threads (root session starts at 0).
[agents.<name>]
table
No
Declares a role.
<name>
is used as the
agent_type
when spawning an agent.
agents.<name>.description
string
No
Human-facing role guidance shown to Codex when it decides which role to use.
agents.<name>.config_file
string (path)
No
Path to a TOML config layer applied to spawned agents for that role.
Notes:
Unknown fields in
[agents.<name>]
are rejected.
agents.max_depth
defaults to
1
, which allows a direct child agent to spawn but prevents deeper nesting.
Relative
config_file
paths are resolved relative to the
config.toml
file that defines the role.
agents.<name>.config_file
is validated at config load time and must point to an existing file.
If a role name matches a built-in role (for example,
explorer
), your user-defined role takes precedence.
If Codex canâ€™t load a role config file, agent spawns can fail until you fix the file.
Any configuration not set by the agent role will be inherited from the parent session.
Example agent roles
Below is an example that overrides the definitions for the built-in
default
and
explorer
agent roles and defines a new
reviewer
role.
Example
~/.codex/config.toml
:
[
agents
.
default
]
description =
"General-purpose helper."
[
agents
.
reviewer
]
description =
"Find security, correctness, and test risks in code."
config_file =
"agents/reviewer.toml"
[
agents
.
explorer
]
description =
"Fast codebase explorer for read-heavy tasks."
config_file =
"agents/custom-explorer.toml"
Example config file for the
reviewer
role (
~/.codex/agents/reviewer.toml
):
model =
"gpt-5.3-codex"
model_reasoning_effort =
"high"
developer_instructions =
"Focus on high priority issues, write tests to validate hypothesis before flagging an issue. When finding security issues give concrete steps on how to reproduce the vulnerability."
Example config file for the
explorer
role (
~/.codex/agents/custom-explorer.toml
):
model =
"gpt-5.3-codex-spark"
model_reasoning_effort =
"medium"
sandbox_mode =
"read-only"